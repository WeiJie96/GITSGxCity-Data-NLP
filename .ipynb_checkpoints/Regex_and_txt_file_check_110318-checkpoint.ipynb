{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import functools\n",
    "import os\n",
    "import re\n",
    "from gensim.summarization import keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(txtfile):\n",
    "    with open(txtfile, 'r') as myfile:\n",
    "        text=myfile.read()\n",
    "    myfile.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-con: txt is a raw text with \\n\n",
    "#post-con: returns text with global redundant words removed\n",
    "def remove_global_redundancies(txt):\n",
    "    #remove figure until citigroup filter\n",
    "    #new stuf\n",
    "    txt = re.sub(\"Figure [0-9]+\\..*? [0-9]+.*?Citigroup.*?\\n\", \"\", txt, re.MULTILINE, re.DOTALL)\n",
    "    txt = re.sub(\"Figure [0-9]+\\..*?Source:.*?\\n\", \"\", txt, re.MULTILINE, re.DOTALL)\n",
    "    txt = re.sub(\"Figure [0-9]+\\..*|figure [0-9]+\\..*|Source:.*|source:.*\", \"\", txt)\n",
    "    txt = re.sub(\"[0-9]+, Citi Research\", \"\", txt)\n",
    "    #change to new\n",
    "    txt = re.sub(\"© [0-9]+.*?\\nCitigroup.*\", \"\", txt)\n",
    "    #new stuff\n",
    "    txt = re.sub(\"© [0-9]+.*?Citigroup.*\", \"\", txt)\n",
    "    txt = re.sub(\".* [0-9]+.*?Citigroup.*\", \"\", txt)\n",
    "    txt = re.sub(\"Citi|Citibank|Citigroup|citi|citibank|citigroup\", \"\", txt)\n",
    "    #new stuff\n",
    "    txt = re.sub(\"[0-9]+|[0-9]+ [0-9]+|[0-9]+ [0-9]+\", \"\", txt)\n",
    "    #commented code removes \"hello. hello. bye?\"\n",
    "    #want to remove \"hello \\n there?\"\n",
    "    #txt = re.sub(\"[\\.\\?!](.*?\\?)\", \"\", txt, re.MULTILINE, re.DOTALL)\n",
    "    #naive solution\n",
    "    txt = re.sub(\".*\\?\", \"\", txt)\n",
    "    txt = re.sub(\"!\", \".\", txt)\n",
    "    txt = re.sub(\"\\r|\\n\", \" \", txt)\n",
    "    \n",
    "    #Remove all letters that are not from ASCII 0-127\n",
    "    #However, would remove things like trademark and registered\n",
    "    txt = re.sub(\"[^\\x00-\\x7f]\", \"\", txt)\n",
    "    \n",
    "    txt = re.sub(\" +\", \" \", txt)\n",
    "    txt = txt.strip()\n",
    "    \n",
    "    return txt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdhd djjj jja dhhd ff ajaj. ss hh. jjj..\n"
     ]
    }
   ],
   "source": [
    "txt1 = read_txt(\"Disruptive Innovation Text\\\\1- Innovating in an Evolving World.txt\")\n",
    "txt2 = read_txt(\"Disruptive Innovation Text\\\\2- All-Solid-State Batteries.txt\")\n",
    "txt3 = read_txt(\"Disruptive Innovation Text\\\\test.txt\")\n",
    "txt4 = read_txt(\"Disruptive Innovation Text\\\\4 - Autonomous Vehicle Networks.txt\")\n",
    "txt6 = read_txt(\"Disruptive Innovation Text\\\\6 - Dynamic Spectrum Access.txt\")\n",
    "\n",
    "print(remove_global_redundancies(txt3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_lst = list()\n",
    "\n",
    "#rudimentary way to check if is txt file\n",
    "for txt in os.listdir(\"Disruptive Innovation Text\"):\n",
    "    if re.match(\".*\\.txt$\", txt) != None:\n",
    "        output_lst.append(\n",
    "            remove_global_redundancies(read_txt(\"Disruptive Innovation Text\\\\\" + txt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)\n",
      "Innovating in an Evolving World: Slow Change with Long-Term Impact Humans are hard-wired to respond to instantaneous change: Our fight or flight response evolved to make snap decisions based on immediate danger. It is not in our nature to identify and react to challenges that arise slowly, even those with great long-term impact on our lives. Businesses face a similar problem when dealing with slow change in their industries. Large-scale societal, economic, and technological trends that emerge gradually and continuously over time can be all too easily overlooked. That is because slow change often occurs outside of an organizations line-of-sight and can arise from the merger of many disparate developments, each of which may be lost in the day-to-day noise. Even the most forward-thinking companies can miss slow change occurring around them: In 2007, Microsoft CEO Steve Ballmer said, There is no chance the iPhone is going to get significant market share.1 By neglecting steady, continuous advancements in computing power and mobile technology, Microsoft missed the smartphone phenomenon and saw its market capitalization fall from $642 billion in 2,3 2000 to $270 billion in 2014. In a time when the average company lifespan on the S&P 500 has dropped from 61 years to 18 years, spotting slow change is critical for long-term stability and growth.4 At , we track slow change by asking which trends are affecting our businesses and clients in ways that are both accelerating and irreversible. The results are evident in exponentially-improved systems that reduce friction or shift society in such a way that returning to the old practices seems inconceivable. By seeking out such patterns in our work at , we have identified three types of change that often cause the biggest impact: (1) Behavioral changes, (2) Technological changes, and (3) Industry or sector changes. The most profound transformations incorporate at least one of these changes, but many often include more. Such is the case with three trends we are currently exploring: (1) changing social structures, (2) the changing nature of transactions, and (3) the changing nature of industries.\n",
      "\n",
      "10)\n",
      "9. Real Estate Market Disruptors FinTech Innovators Are Changing the Way We Trade Houses Buying and selling a home is one of the more stressful life events many will go through. If you have ever done it, you may have dealt with highly irrational counterparties, the stress of always keeping a home show-ready, or having had to sweat out transaction details like title search issues or drawn-out loan underwriting. And all of this happened with brokers who earn ~5% commission from the seller and take zero principal risk. A growing group of intrepid FinTech firms in Europe and the U.S. are deploying models to displace this traditional real estate brokerage model. Many of these new businesses are executing strategies that aim to speed the transaction timeline for buyers and sellers while lowering overall transaction costs (financial and/or emotional). Some of the many different business models currently in play are listed below but for simplicity, our primarily focus will be on the first strategy: Instant Offers (I-Buyer Model): Several companies, both public and private, are now deploying strategies that provide offers on homes to willing sellers. Offer prices factor in a discount that looks similar to a broker commission, but closing times can be as few as weeks for the seller versus months. The company takes ownership of the property, potentially makes repairs, and sells the home through various potential channels. Customer-led Vertical Integration: This is a strategy in which a company identifies potential buyers and works with them to purchase a home. This is very similar to a broker model, but in this case the company makes a cash offer on the chosen home and carries the property while the ultimate owner arranges financing. The value-add is that cash offers may be accepted and potential buyers can avoid a bidding war. Fixed Broker Fees: This strategy simply charges a fixed fee as opposed to a percentage commission. Companies involved in this strategy leverage the democratization of data and employ technology platforms to help drive efficiencies in their broker network. Framing the Scope of the Issue Housing is 15% of GDP in the U.S. and the largest asset class on household balance sheets, with $1.5 trillion worth of residential real estate sold annually. Thats 10x the size of Treasury bond issuance being transacted via direct negotiation, and it happens between buyers and sellers who are 5x20x levered in most cases. Because it is such a concentrated storage of wealth and such a large source of household debt, liquidity and transaction speed are meaningful to the average home seller. In May of this year, the peak of the selling season, the median amount of time homes had been listed for sale was 55 days. The carrying cost over this amount of time could be as much as 1% of the homes value. Not to mention the economic impact this delay has due to impaired household mobility. It would be like needing a new car, but having to wait and sell your current car on craigslist before you could buy a new one. Theres no dealership trade-in option for moving, and the cost of this delay to a home seller is about as much asthe down payment on a car. \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 61 Post the bursting of the housing bubble in the U.S., many innovations have emerged to disrupt the cost of brokering the sale of a home The financial crisis and burst of the housing bubble in the U.S. are well documented. Financial institutions failed, housing credit availability dried up, and government intervention occurred on many levels to stabilize and regulate the industry. Home prices fell ~26% nationally during this period, and some metro areas like Phoenix and Las Vegas are still ~20% below their previous peak more than ten years later. During the post-crash period, many innovations and developments took place that led the industry to make attempts to finally disrupt the cost of brokering the sale of a home. We generally attribute this disruption to a few key drivers: Democratization of data: Websites and data providers started publicly posting residential real estate listings as early as 2006. This democratization of data has grown consistently over time and moved into mobile. What was once only available to real estate agents on the Multiple Listing Service (MLS) is now available to virtually everyone via apps on their smart phones. Most of this democratization, however, has been driven by broker advertising revenue. Proof of concept in mortgage originations: Its no surprise the U.S. financial crisis yielded regulation in housing finance. Lenders are now required to start verifying, documenting, and reporting borrower credit characteristics to a much higher standard, and non-compliance bears significant consequences. These heightened standards drove a desperately-needed technology update, and FinTech lenders have proven their ability to leverage technology and boost efficiency. In a recent staff paper from the New York Federal Reserve, analysts examined loan-level origination data and found that FinTech lenders are able to close a mortgage transaction 20 percent faster than their non-tech counterparts. Borrower defaults were significantly lower as well (38% lower for Federal HousingAdministration (FHA) purchase loans and 29% for refinance originations). A developing and unprecedented wave of housing demand: Several general housing market themes are helping to provide FinTech firms runway to disrupt the status quo. Since the fall of home prices from the peak, the pace of home sales has steadily risen and the inventory of homes for sale has fallen (Figure 37). Some of this light supply is because single-family home building still lags in recovery (Figure 38). This national trend of rising demand and falling supply has been supportive of home prices, which have appreciated at ~5.6% per year on average for the past four years. Stable, slowly rising home prices benefit these strategies because there is reasonable confidence asset prices wont fall. And home ownership demand is likely to rise even more as the millennial generation enters the next stage of their lives, albeit later than previous generations (Figure 39). And its important to remember that this wave of demand will be increasingly tech-friendly and will likely expect all transactions to happen quickly and efficiently. \f",
      " 6262 GPS: Global Perspectives & Solutions August 2018 old bucket % of population shown is for 23-34yr olds only) In the traditional home sales model using an agent, the seller hires an agent who is responsible for marketing the home and attracting buyers. This process usually takes 23 months, during which time it is commonplace for the agent to conduct walk-throughs with prospective buyers.After an offer is received, the seller often has to wait for the borrower to finalize his or her financing to begin the closing process. At the end of this process, the seller pays 3%6% of the sales proceeds as commission to the real estate agents. To get a sense of how much potential revenue exists in the space, existing home sale counts and median sale prices along with an assumed 5% of total market value amounted to ~$68 billion in 2017 potential commission revenue (Figure 40). In contrast, the iBuyer model is a transition from the agent-based advisory system to a dealer-based system, where compensation is derived from a bid-ask spread rather than a commission. Specifically, the iBuyer firm will assess the value of the property and offer a bid to purchase the home from the seller at a discount. The iBuyer firm then relists the property and attempts to resell for full value, capturing the difference between the discounted acquisition price and the full value resale price as revenue. The value proposition to home sellers in the iBuyer model is the ability to move on a short and definite timeline that eliminates the stressful waiting game and inconvenience of showings and open houses. Additionally, by using advanced analytic techniques for valuation and the prime collateral status of vacant, move-in ready homes for financing, iBuyer firms believe it is possible for the discount to be comparable to the traditional commission amount. In other words, a seller could sell his or her home in a matter of a couple weeks with the same expected net proceeds as the traditional, multiple-month process. For buyers, the vacant state of the home allows for flexible move-in dates. Additionally, many iBuyer firms offer trial periods and warranties on core infrastructure that offer peace of mind. In the longer term, we expect the iBuyer firms to also build out mortgage origination businesses. Because the iBuyer firm will have already done a title search and an appraisal during the acquisition process, this could potentially be removed from the lending process due to redundancy thereby lowering the cost and time to close. \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 63 In short, an iBuyer as central liquidity provider could better accommodate the needs of buyers and sellers independently than they are able to accommodate each other, all at a competitive cost. This should be surprising to those familiar with the financial markets, as all-to-all markets are reserved for the most liquid and fungible assets, while illiquid and harder to value financial assets are the purview of dealers. Because residential real estate is retail, highly capital-intensive, and reliant on nuanced hyperlocal economic data, the market developed as an exception to this rule. But given the advancements in data availability and analysis as well as the trends in financial markets, we believe a reversion could be taking place. Other Follow-on Opportunities But the shift in business model does not and should not end with just buying and selling properties. There are differing strategies that take advantage of the holding period and unlock value by making nominal improvements/updates and repairs. Borrowers could find this attractive because the broker will likely have access to much cheaper financing to conduct these projects, and it can all be rolled into the borrowers mortgage versus a higher-cost construction loan. Other strategies might involve offering additional services to a home buyer such as preferred vendor services like snow removal, landscaping, and HVAC maintenance (something akin to an online marketplace that shows you what other customers purchased). We also envision a joint venture strategy that works with home builders to help potential sellers effectively trade in their old home for new construction. Finally, these companies might also align with the growing industry of institutional owners of rental properties, providing these real estate investment trusts (REITs) a supply of homes. While these strategies are certainly poised to change the way we trade homes in the U.S. and abroad, there are several challenges and barriers to entry. First, a significant amount of capital is required to purchase, carry, repair, and sell homes. Second, this strategy also requires a reasonable amount of liquidity in a given housing market to confidently establish reliable home-price levels. And liquidity isnt just by geography; liquidity could also be different by price point. These strategies may not work on, for example, the highest and lowest price points in a given area since liquidity is likely lower. There may be cases where the traditional broker model could co-exist alongside these liquidity providers, operating at the price tails. Additionally, the shifting age demographics of the U.S. might become a risk. Home prices may experience weakness as baby boomers move to either downsize their living situation by purchasing smaller homes or switching to renting. If millennials are either unwilling or unable to purchase these homes, there could be a scenario where home prices correct. Finally, regional expertise is still required to inspect and verify property pricing to protect against losses. Traditional Business Models to Change The stage is set. FinTech firms are positioning to upend the industry, and their innovations will likely produce winners and losers. Existing brokerage models that only collect advisory/commission fees will likely suffer as buyers and sellers are attracted to faster transaction times and potentially lower bid/ask spreads. Several of these legacy brokers have already announced small initiatives to adapt. Other companies that rely on broker advertising revenue could also suffer. We are already seeing home builders, real estate data providers, rental operators, mortgage lenders, and others starting to discuss the industry development in their public filings in a positive tone, and we expect existing FinTech players to take significant market share in the coming years as they shorten the timeline for buyers and sellers. \f",
      " 6464 GPS: Global Perspectives & Solutions August 2018 Ross Barrows Head of Australian Small Cap Research Team Ultimately, voice-activated controls free an individual from being constantly tethered to a specific device. It is expected that in 2019, 20% of all user interactions with the smartphone will be via Smart Assistants Artificial Intelligence is the next paradigm shift in the technology sector\n",
      "\n",
      "11)\n",
      "10. Smart Voice-ActivatedAssistants Machines Learn, but People Teach Advancements in voice recognition, natural language processing, and improved connectivity have made voice control of electronic appliances and smart devices increasingly mainstream. We believe we are at the tipping point for user interfaces with the emergence of voice-based digital assistants such as Amazons Alexa, Apples Siri, Googles Now, Microsofts Cortana, etc. Voice is well positioned to permeate a large number of industries to varying degrees. These smart assistants have opened a new page in human-machine interaction. Smart Assistants or Virtual PersonalAssistants require advanced speech recognition and speech synthesis algorithms in order to comprehend and respond to commands. We expect a rise in the usage of Smart Assistants to result in them performing more complex tasks. In 2019, 20%21 of all user interactions with a smartphone are expected to be via SmartAssistants. Currently, Smart Assistants fulfill simple tasks like setting alarms and retrieving information from the web, but in the near future they would be able to deliver complex tasks such as completing a transaction based on historical patterns. This trend would be further intensified by conversational commerce, voice-based payments, and speech recognition security systems. Powered byArtificial Intelligence The emergence of SmartAssistants has been made possible by advancements in artificial intelligence (AI). The McKinsey Global Institute estimates that deep learning techniques (focusing on three neural networks: feed forward, recurrent and convolutional) could enable the creation of $3.5$5.8 trillion in value annually. s Global Technology team sees the rise of AI as the next paradigm shift in the technology sector. IDC forecasts the market size for AI solutions to grow at a 55% compound annual growth rate, from $8 billion in 2016 to $47 billion in 2020, driven by the deployment of AI systems in automated customer service agents, quality management investigation and recommendation systems, diagnosis and treatment systems, and fraud analysis and investigation. Figure 42 and Figure 43 show the forecast nine-year compound annual growth rate forAI revenue at +57% (albeit off a low base) and for cognitive computing to more grow more than five-fold from 2019 to 2024. 21 Gartner Inc. Annual Mobile Apps Survey \f",
      " 6565 August 2018 GPS: Global Perspectives & Solutions Applications We see the following applications of Smart Assistants as driving their increasing use: 1. Smart Speakers and TVs Smart Assistants have resulted in speakers transforming from an audio device to devices that can answer questions as well as complete tasks. Smart speaker shipments are expected to grow at a 35% compound annual growth rate from 32 million units in 2017 to 142 million units in 2022 (Figure 45), which includes doubling from 201922. Another indicator of the increasing use of smart speakers is the number of skills being added to Amazons Echo andAlexa. At the end of March quarter 2018, developers had built more than 30,000 skills to date, doublingAlexas capabilities in 9 months (Figure 46). According to IHS Markit, the integration of Amazon Alexa and Google Assistant is expected to increase the demand for smart TVs going forward. \f",
      " 6666 GPS: Global Perspectives & Solutions August 2018 ComScore estimates that 50% of all searches will be by voice by 2020 One of the challenges facing search is prominence. 2. Voice-Enabled Search ComScore estimates that 50% of all searches will be by voice by 2020. Voice search queries are different from normal text search queries as voice searches are more conversational (i.e., BHP CEO vs. Who is the CEO of BHP) and more nuanced. With text search, while there is always one primary search result at the top, the person entering the query can also easily see and scan the other, say nine, search results. With voice search results, however, being in the top 23 search results becomes even more critical because someone is unlikely to listen to nine more search results being recited. This is most likely an issue when a search is generic such as batteries or toothpaste and may prove less of an issue for leading branded products and more of an issue for challenger brands. This is most important for first-time purchases, as the assistant will learn a users preferences over time. 3. Navigation & Automotive Another application of voice activated assistants is in the automotive industry. Driving presents a natural setting for the application of voice-based systems given that both hands and eyes are usually occupied. Figure 47 and Figure 48 below gives the primary reasons for usage of voice-based search and the primary places where it is used. ALong Way To Go We believe increased Internet penetration will increase the need for multilingual content as new users will be predominantly from non-English speaking regions. Our analysis of the languages supported by the major Smart Assistants highlights the extent of the limitation on supported languages. For instance,Amazons Alexa currently only supports English (U.S. and U.K. English) and German (it has recently added Japanese (Figure 49)). \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 67 Australian Stock Exchange-listed Appen is At present,Asian language speakers dominate the Internet users pie, but Internet content is heavily skewed toward English (refer Figure 50 and Figure 51). We expect the leading technology companies to increase their focus on non-English languages, especiallyAsian languages and dialects, over the medium term. There is an underlying need for local content, which should increase the need for language resources going forward as companies try to attract consumers from these regions. \f",
      " 6868 GPS: Global Perspectives & Solutions August 2018 Increased services result in increased products being bought which may be powered by semiconductors which may be supported in data centers. Who Is In addition to the companies that develop the Smart Assistants, we note these second-order beneficiaries from increasing use of Smart Assistants: Data/Service Providers: In order for SmartAssistants to evolve, there is a need for large volume and variety of labelled-training data, which is a growth opportunity for technology services/data providers. Home Electronics Manufacturers: The increasing use of Smart Assistants in speakers, TVs, etc. could result in consumers upgrading their home electronics. Semiconductors: Semiconductor companies are expected to benefit from the increasing use of Smart Assistants and artificial intelligence. Data Center Providers: We also see data center providers as benefiting from the increased data required to power the AI algorithms. Improved Technology Is a Key Risk for Suppliers While we believe the likely outcomes for the development of voice-activated technologies are somewhat binary, in that we expect strong growth, the companies providing the training data, voice in particular, could be challenged over time. The , but we dont see that any time soon. The Argument for the Positive By one estimate, a supervised deep-learning algorithm will generally achieve acceptable performance with around 5,000 labeled examples per category and will match or exceed human level performance when trained with a data set containing at least 10 million labeled examples.22 Most currentAI models appear to be trained through supervised learning with almost three-quarters of the impact from advanced analytics which are tied to use cases requiring millions of labeled data examples.23 Also AI systems need retraining, with one-third of use cases needing monthly updating, and just under 10% needing weekly refreshing.24 Lastly, training data is often labelled manually and sufficiently large and comprehensive data sets required for training are difficult to find, but those with sufficiently large data sets are well placed. Ironically, in supervised leaning, machines are taught, they dont learn by themselves,25 reinforcing our view that Machines Learn, but People Teach. 22 Ian Goodfellow, Yoshua Bengio and Aaron Courville, Deep learning, MIT Press, 2016. 23 McKinsey Global Institute, Notes from the AI Frontier. April 2018. 24 Ibid. 25 Ibid. \f",
      " 6969 August 2018 GPS: Global Perspectives & Solutions The Argument for the Negative According to NVIDIA, CPU Deep Learning performance improved 65x in the four years to 2016 (Figure 52). Material use of supervised learning will likely result in ongoing demand for companies providing the training data, but if unsupervised learning where machine learning algorithms draw inferences from datasets consisting of input data without labeled responses materially displaces supervised learning, companies providing the training data could be challenged over time.\n",
      "\n",
      "12)\n",
      "Disruptive Innovation Ideas from the Past \f",
      " Mobile Payments could see a transaction value of $1trn by 2016 PayTV industry only added 200k subs in 2012 vs. 2mn at its peak while streaming subs are increasing exponentially US sales for compressed natural gas (CNG) vehicles could surpass 100,000 by 2020 The cost per genome in DNA sequencing has fallen from $100m in 2001 to < $10k today The 3D printing market is expected to be worth $6.5bn by 2019 The e-cigarette market could have compound annual growth of near 50% 100,000,000 Subsea processing equipment has potential to be a $100bn pa market by the next decade 10,000 $6.5bn 2013 group Theres big opportunity out there Disruptive InnovationsMobile Payments could see a transaction value of $1trn by 2016 PayTV industry only added 200k subs in 2012 vs. 2mn at its peak while streaming subs are increasing exponentially US sales for compressed natural gas (CNG) vehicles could surpass 100,000 by 2020 The cost per genome in DNA sequencing has fallen from $100m in 2001 to < $10k today The 3D printing market is expected to be worth $6.5bn by 2019 The e-cigarette market could have compound annual growth of near 50% 100,000,000 Subsea processing equipment has potential to be a $100bn pa market by the next decade 10,000 $6.5bn 2013 group Theres big opportunity out there Disruptive Innovations \f",
      " 2012 8% 70% 2035 Solar could see $1.3trnof investment in new capacity from 2012-35 Software as a Service (Saas) currently 8% of total software wallet is expected to grow to 70% of budget over time 2013 $360mn 2016 $3,700mn Software Defined Networking (SDN) is expected to grow from just under $360mn in 2013 to $3.7bn in 2016 \f",
      " Theresbig opportunity out there Digital Marketing Real time bidding based digital ad spendis expected to reach nearly 60% of total display and mobile spend by 2016, a 3 yr CAGR of 66% Electric Vehicles $10k .More than 200 digital currencies exist today, with 12 having marketing capitalizations > $5 million $5m Digital Currency (i.e. Bitcoin) 4D Printing 4D printing takes 3D printing to the next level by directing the object to change shape and potentially selfassemble Digital Banking Global m payment volumes are expected to total $447 billion by 2016, a 3 year CAGR of 86% Introducing a battery operator servicing model could reduce the cost of an electric car to the $10k range 60% 2016 Theresbig opportunity out there Digital Marketing Real time bidding based digital ad spendis expected to reach nearly 60% of total display and mobile spend by 2016, a 3 yr CAGR of 66% Electric Vehicles $10k .More than 200 digital currencies exist today, with 12 having marketing capitalizations > $5 million $5m Digital Currency (i.e. Bitcoin) 4D Printing 4D printing takes 3D printing to the next level by directing the object to change shape and potentially selfassemble Digital Banking Global m payment volumes are expected to total $447 billion by 2016, a 3 year CAGR of 86% Introducing a battery operator servicing model could reduce the cost of an electric car to the $10k range 60% 2016 \f",
      " The market for industrial robots is forecast to grow with almost 200k units expected to be sold in 2016 Robots $25bn 2012 $30bn 2016E billion by 2015 $60 Insurance Securitization Since 2012, the new issue market for insurance -linked securities has grown by 30% per year and issuance could be $60 billion by 2015 Energy Storage The economic value of energy storage over a 10-year period in the US could be $228 billion, 21% of the $1 trillion global economic benefi t Precision Agriculture To support a population that is growing by ~75 million people per year, agricultural producers will need to boost production of key crops by 20%, on average, over the next decade Immunotherapy Immunotherapy has the potential to turn cancer into something akin to a chronic disease a $35 billion opportunity $35 billi n \f",
      " Theres big opportunity out there Disruptive Innovations III Machine Learning/Artificial Intelligence Humans can manage about seven variables in their working memory vs. computers which have no limit By 2030, driverless cars could be a $100 billion market Autonomous Driving Drones Almost 800 million small packages could be delivered by drones in the US Biosimilars Biosimilars are poised to take over $110 billion in revenues from drug innovators over the next 10 years. Floating LNG The length of Shells new FLNG facility is equivalent in size to the Eiffel Tower standing on top of the Taj Mahal \f",
      " Public API The rate of adoption for APIs has increased exponentially, similar to the adoption rate for smartphones Marketplace Banking Sharing Economy The five most prominent sharing economy sectors could rise to $335 billion from just $15 billion today Robo-Advisors Virtual Reality Starting with game makers and goggle-like game terminals in 2016, theVR/ AR market could rise to $200 billion in the first5years The total addressable market for P2P lending is $254bn, or 8% of the total US consumer credit market From just $19 billion at end-2014 the target addressable market for Robo Advisors could rise to $5 trillion over the next 5 to 10 years \f",
      " 2016 group Theres a big opportunity out there Disruptive Innovations IVWide Bandgap Semiconductors Wide bandgap semiconductors let devices operate at much higher temperatures, voltages, and frequencies while being smaller and more reliable. Home Networking Consumer media devices could be the focal point of the connected home, integrating a variety of services and connectivity into one location. The Future Look of Devices Consumer devices by 2021 could look like a thin and flexible piece of paper through the use of flexible OLED technology. Epigenetics Epigenetic approaches in cancer treatment could become a $10bn market by 2025. Energy: The Big Data Revolution Big data analytics would make producing oil/gas faster and cheaper, renewables forecasting more accurate, and the transport-generation- storage model more integrated. 2016 group Theres a big opportunity out there Disruptive Innovations IVWide Bandgap Semiconductors Wide bandgap semiconductors let devices operate at much higher temperatures, voltages, and frequencies while being smaller and more reliable. Home Networking Consumer media devices could be the focal point of the connected home, integrating a variety of services and connectivity into one location. The Future Look of Devices Consumer devices by 2021 could look like a thin and flexible piece of paper through the use of flexible OLED technology. Epigenetics Epigenetic approaches in cancer treatment could become a $10bn market by 2025. Energy: The Big Data Revolution Big data analytics would make producing oil/gas faster and cheaper, renewables forecasting more accurate, and the transport-generation- storage model more integrated. \f",
      " Open-Source Robotics The use of open- source software in robots can accelerate robot penetration by lowering customer adoption cost. Contextual Commerce Increasingly, online purchases will be suggested and transacted through non-traditional e-commerce sites such as social media. Direct-to-Consumer Marketplace Moving from proximity- sourced product to a direct-to-consumer marketplace would create a $200bn annual revenue opportunity for apparel manufacturers. Thermoplastic Subsea Pipes Switching from traditional steel pipes to new thermoplastic pipes decreases subsea costs by 30-40% and total deepwater costs by 10%, enough to lower the breakeven oil price by $4/bbl. Next Gen Ocular Drug Delivery New delivery methods will increase the ease and effectiveness of drug delivery for the growing number of people with ocular disease. Open-Source Robotics The use of open- source software in robots can accelerate robot penetration by lowering customer adoption cost. Contextual Commerce Increasingly, online purchases will be suggested and transacted through non-traditional e-commerce sites such as social media. Direct-to-Consumer Marketplace Moving from proximity- sourced product to a direct-to-consumer marketplace would create a $200bn annual revenue opportunity for apparel manufacturers. Thermoplastic Subsea Pipes Switching from traditional steel pipes to new thermoplastic pipes decreases subsea costs by 30-40% and total deepwater costs by 10%, enough to lower the breakeven oil price by $4/bbl. Next Gen Ocular Drug Delivery New delivery methods will increase the ease and effectiveness of drug delivery for the growing number of people with ocular disease. \f",
      " 2017 group CRISPR-Based Gene Editing Still in its infancy, the worldwide CRISPR technologies market is expected to grow to ~$10 billion by 2025 Smart Robotic Tools End-of-arm tools that mimic human hand capabilities could change how robots are used The Rise of the zen Developer Low-code development platforms enable zen developers to build professional-grade applications with little formal software development training Heat Not Burn Tobacco Heat Not Burn products provide the taste of tobacco without the smell and harmful smoke Unmanned Commercial Aircraft The deployment of robot pilots on commercial fl ights could improve the safety record, profi tability and effi ciency of the airline industry A Galaxy of Opportunities \f",
      " Passive Investing and New Pricing Models Sliding management fees based on relative performance could help active managers compete against the growing popularity of passive funds Internet of Things Payment Adding a payments layer to IoT applications helps in the proliferation and monetization of IoT Hyperloop A system of vacuum-sealed tubes are planned that can propel capsules with people or freight up to 760mph faster than air travel Liquid Biopsy Liquid biopsy could be a $10 billion+ market over the next decade as one of the most important clinical advancements in cancer detection Blockchain and Commodities Trading of physical commodities and electricity markets could be signifi cantly changed by the use of blockchain \f",
      " Global Perspectives & Solutions ( GPS) is designed to help our clients navigate this designed to help our clients navigate the global economys most demanding challenges, identify future themes and trends, and help our clients profit in a fast-changing and interconnected world. GPS accesses the best elements of our global conversation and harvests the thought leadership of a wide range of senior professionals across the firm. All GPS reports are available on our website www..com/gps Putting the Band Back Together Remastering the World of Music August 2018 Electric Vehicles Ready(ing) For Adoption June 2018 Disruptors at the Gate Strategic M&A for Managing Disruptive Innovation April 2018 The Public Wealth of es How to Turn Around es Fortunes by Unlocking Public Assets March 2018 Securing India's Growth Over the Next Decade Twin Pillars of Investment & Productivity February 2018 2018 Corporate Finance Priorities January 2018 Disruptive Innovations V Ten More Things to Stop and Think About November 2017 Inequality and Prosperity in the Industrialized World Addressing a Growing Challenge September 2017 UN Sustainable Development Goals A Systematic Framework for Aligning Investment June 2018 ePrivacy and Data Protection Privacy Matters: Navigating the New World of Data Protection May 2018 Sustainable es Beacons of Light Against the Shadow of Unplanned Urbanization April 2018 The Bank of the Future The ABCs of Digital Disruption in Finance March 2018 Investment Themes in 2018 How Much Longer Can the January 2018 China Entering a New Political Economy Cycle The World According to Xi Jinping Thought December 2017 Women in the Economy II How Implementing a Womens Economic Empowerment Agenda Can Shape the Global Economy November 2017 Technology at Work v3.0 Automating e-Commerce from Click to Pick to Door August 2017 \f",
      " Education: Back to Basics Solutions for The Global Water Crisis Is Education Fit for the Future July 2017 The End of Free and Cheap Water April 2017 ePrivacy & Data Protection How Regulation Could Alter the Path of Innovation March 2017 2017 Corporate Finance Priorities January 2017 Digital Disruption -Revisited What FinTech VC Investments Tells Us About a Changing Industry January 2017 2017 Investment Themes A Wind of Change January 2017 Infrastructure for Growth The dawn of a new multi-trillion dollar asset class October 2016 Virtual & Augmented Reality Are you sure it isnt October 2016 The Coming Pensions Crisis Recommendations for Keeping the Global Pensions System Afloat March 2016 Investment Themes in 2016 New Normal or No Normal January 2016 Global Political Risk The New Convergence between Geopolitical and Vox Populi Risks January 2016 The Curtain Falls How Silicon Valley is Challenging Hollywood October 2015 Car of the Future v3.0 Mobility 2030 November 2016 Re-Birth of Telecoms into a New Digital Industry Time to Dump the Dumb Pipe October 2016 Disruptive Innovations IV Ten More Things to Stop and Think About July 2016 Digital Disruption How FinTech is Forcing Banking to a Tipping Point March 2016 Technology at Work v2.0 The Future is Not What It Used To be January 2016 Energy 2030 Financing A Greener Future November 2015 \f",
      " 84 84 GPS: Global Perspectives & Solutions August 2018 Notes 2018 group \f",
      " August 2018 GPS: Global Perspectives & Solutions 85 Notes 2018 group \f",
      " 86 86 GPS: Global Perspectives & Solutions August 2018\n",
      "\n",
      "2)\n",
      "1. All-Solid-State Batteries ADeterminant for Battery Electric Vehicle Uptake There is no denying that the recent boom in battery electric vehicles (BEVs) is partly the result of ideals promoted by governments, regulation, and corporate ethics. So far, there is no BEV capable of meeting consumer needs the same way an internal combustion engine (ICE) vehicle can, and based on the roadmaps announced by carmakers, there is no sign that one will emerge for the first half of the 2020s. It is not an easy task to develop a BEV that, like current ICE vehicles, can be refueled in three minutes, has a 1,000km range on one tank of fuel, benefits from sufficient infrastructure, and can be easily used for at least 10 years. However, the emergence of all-solid-state batteries may disrupt the current situation and greatly accelerate market uptake of BEVs. When the lithium-ion batteries that are widely used in smartphones and other miniaturized electronic devices are used in automotive applications, they require much higher demands in terms of safety and battery lifespan. At the same time, there is a trade-off between improvements in range which essentially require an increase in energy density and safety/lifespan. This trade-off is the main reason why the performance of current lithium-ion batteries is seen as a possibly insurmountable barrier to the increased market uptake of electric vehicles. We believe all-solid-state batteries have the potential to overcome these problems. All-solid-state batteries have a long history. Solid electrolytes were developed in the 1970s, but insufficient ionic conductivity limited their application. However, solid electrolytes with ionic conductivity similar to or superior to liquid electrolytes have recently been discovered, accelerating research and development efforts. At the 2017 Tokyo Motor Show, Toyota announced a target for commercialization for all- solid-state BEVs in the first half of the 2020s. Although the first generation of BEVs using all-solid-state batteries that are due to be launched by Toyota will only have a limited production volume, the announcement by the company will undoubtedly stimulate increased efforts by many companies, researchers, and government bodies in the development of all-solid-state batteries. Volkswagen, Hyundai Motor, and Nissan Motor have all announced investments in start-up companies, so we see this as a theme likely to benefit from greatly increasing attention. Masahiro Tatsumisago, Zenkotai Denchi no Kaihatsu Jokyo (Development of All-Solid-State Batteries), Journal of Society of Automotive Engineers of Japan, Vol.72, No.2, \f",
      " 1313 August 2018 GPS: Global Perspectives & Solutions Akitoshi Hayashi, Masahiro Tatsumisago, Zenkotai Denchi no Kaihatsu Jokyo (Development of All-Solid-State Batteries), Journal of Society of Automotive Engineers of Japan, Vol.72, No.2, Potential to solve issues of range, degradation of performance, and charging time, etc. Potential of All-Solid-State Batteries Current lithium-ion batteries are made up of the cathode, an electrolytic solution, a separator, and the anode. The difference in a solid-state battery is that the electrolyte is solid. In fact, all components and materials are solid, hence the solid- state terminology. The properties of all-solid-state batteries depend on which materials are used, but research-to-date reveals a clear potential in terms of safety, resistance to leakage, resistance to combustion (simplified cooling structure), miniaturization, flexibility of design in terms of direct layer formation for cells, relative long discharge cycle lifespan, lack of degradation thanks to good high/low temperature properties, short charge times, high energy density, and high power density. In the past, low power density has been seen as a weakness of solid-state batteries, but the Tokyo Institute of Technology and Toyotas research team have together developed an all-solid-state battery with three times the power density and twice the energy density of existing lithium-ion batteries. We believe all-solid-state batteries have the potential to overcome the disadvantages of EVs. \f",
      " 1414 GPS: Global Perspectives & Solutions August 2018 \f",
      " 1515 August 2018 GPS: Global Perspectives & Solutions Impact of Market Uptake of All-Solid-State Batteries The main impacts of all-solid-state batteries on the auto industry include an acceleration in BEV market uptake and changes in the BEV battery supply chain. If BEVs replace ICE vehicles, there would be no need for engines, transmissions, and related parts, but there would be a new need for batteries, inverters, motors, and parts related to these systems. For conventional auto assemblers, which manufacture engines and transmissions in-house, ensuring that they have the capacity to develop all-solid-state batteries in-house is an important source of added value. For suppliers, it will be important to re-examine elemental technologies to develop new components. If there is an increase in BEV market uptake, there are also likely to be changes to national-level rules governing things such as taxes, energy policy, and resources. Ashift from liquid lithium-ion batteries to all-solid-state batteries would also mean a change from liquid electrolytes to solid electrolytes and a decrease in the need for separators, and there would be the potential to use new materials for cathodes and anodes. We think it likely that the materials used in the all-solid-state batteries to be launched by Toyota in the first half of the 2020s will be similar to those used currently, and as production volumes will be small, the impact on the current supply chain is also likely to be small. However, if we see material progress in research and development efforts, the all-solid-state batteries available in the second half of the 2020s and the 2030s are likely to be disruptive. \f",
      " 1616 GPS: Global Perspectives & Solutions August 2018 Barriers to Market-Uptake of All-Solid-State Batteries There has been talk of a bias to BEVs, but the current market consensus is that we are now in an era of powertrain diversification rather than the coming of age of BEVs as such. However, we think that if efforts to develop volume production of all- solid-state batteries are successful, the era of the BEV could be close. Even so, a range of issues would need to be overcome. Research and development aimed at the volume production of all-solid-state batteries has only just begun, and how far manufacturing costs will decline is still unclear. Theoretically, there should be considerable potential for costs to decline, given the simplification of battery packs and the use of low-cost electrode materials. On the other hand, if there is greater-than-expected progress in the improvement of lithium-ion battery performance and increased reductions in cost, the shift to all- solid-state batteries could be delayed. There is also the risk that interest in BEVs themselves could fade because of developments in hybrid electric vehicles (HEVs) and standard ICE vehicles, the debate around well-to-wheel issues, and the renewed popularity of diesel vehicles all of which could mean a weakening in development efforts for all-solid-state batteries. From the perspective of range and the time required for hydrogen refueling, fuel-cell vehicles are another potential competitor. Although infrastructure issues are a problem, there is considerable potential in terms of a fossil-fuel substitute and energy carriage. KPMGs GlobalAutomotive Executive 2018 survey ranked fuel-cell vehicles as the top key trend through 2025 and BEVs in the 3rd position according to global automotive executives. In 2017, the same survey had the issues reversed, with BEVs in the No. 1 position and fuel-cell vehicles ranked 3rd. \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 17 Yigal Nochomovitz, Ph.D. U.S. Mid/Small Cap Biotechnology Analyst Samantha Semenkow, Ph.D. U.S. Mid/Small Biotechnology Team Eye Institute; Alzheimer's Associate\n",
      "\n",
      "3)\n",
      "2. Anti-Aging Medicines Advancing Health by Turning Back Time The legend of the restorative powers of the Fountain of Youth has fascinated human civilization throughout the generations, dating all the way back to the Greeks (e.g., Herodotus). Other hypothetical conduits for a return to a state of youthfulness (e.g. the Philosophers Stone) have featured prominently throughout human civilization as alluring, but equally elusive. Fast forward to 2018, and very recent cutting-edge scientific breakthroughs may, at long last, fundamentally explain why we age. This rapid scientific progress could spawn FDA-approved therapeutics potentially in the next decade, with the primary goal of keeping us younger and alive for longer. Today, the anti-aging market, while huge (~$200 billion globally), is largely restricted to non-therapeutics (cosmetic products and procedures).At the same time, U.S. health spending, which increases significantly with age in concordance with age- related diseases (see Figure 8), is expected to exceed ~20% of U.S. gross domestic product (GDP) by 2025. Thus, with scientific breakthroughs emerging this decade on the cellular origins of why the tissues in our bodys age, novel anti-aging medicines may become one of the next big disruptions in the healthcare market. Prior Attempts There has been a range of prior attempts by the Biopharmaceutical industry over the last several decades to develop anti-aging therapeutics, including the activation of so-called sirtuin proteins (via resveratrol, a component found in red wine) and the enzyme telomerase (increasing healthy cell division by activating telomerase), but all the studies were unsuccessful (see Figure 9). However, the science and technology necessary for developing therapies capable of slowing/reversing or potentially preventing the onset of age-related diseases has advanced dramatically in recent years, to a point where effective anti-aging drugs may soon become a reality. \f",
      " 1818 GPS: Global Perspectives & Solutions August 2018 Anti-Aging Players Many biotech companies, including Unity Biotechnology and Calico (a Google venture), are developing therapies with the goal of extending the human healthspan defined as the portion of life lived free of age-related disease. These companies are exploring a number of potentially transformative approaches, including circulating youth factors, mitochondrial dysfunction, and the elimination of a specific cell type called senescent cells. In our view, targeting these so-called senescent cells, which are believed to be the drivers of numerous age-related diseases, appears to be the most promising anti-aging approach explored thus far (Figure 9). Unity Biotechnology is developing a novel class of drugs called senolytics that are specifically designed to eliminate senescent cells while sparing the normal surrounding tissues. Recently, Unity advanced its first senolytic into the clinic for osteoarthritis of the knee, a disease that affects over 15 million patients in the UnitedStates. If successful, senolytics could become FDA approved and commercially available within the next five years (Figure 10). Senescent Cells: A Potential Underlying Cause of Age- Senescent cells have been shown to accumulate in tissues with age and are associated with a number of age-related diseases, including atherosclerosis (plaque buildup in artery walls), arthritis, retinal degeneration, Alzheimers disease, and many forms of fibrosis (a thickening of connective tissue) (Figure 8). The induction of senescence is thought to be an acute defense mechanism against cancer and other forms of cellular dysfunction. To be more specific, in response to stress, cells can permanently stop dividing (i.e., senescence) and therefore provide a barrier to the development of cancer. Senescent cells have also been shown to produce and secrete a distinct cocktail of pro-inflammatory proteins and growth factors (Figure 11). It's hypothesized that these secreted factors are programmed to (1) induce an inflammatory response that can stimulate the clearance of nearby damaged or potentially cancerous tissue and (2) close the loop and then eliminate acute senescent cells after their job is done. Unfortunately, things arent so simple, and while the senescent cells should disappear, sometimes they persist in tissues. \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 19 This accumulation of senescent cells can lead to chronic senescence (as opposed to acute senescence), and scientists have discovered that chronic senescence drives/contributes to age-related diseases. Therefore, use of drugs that can flush out the chronic senescent cells looks like an attractive therapeutic strategy. Selectively Eliminating Senescent Cells Could Prevent and Possibly Reverse Age-Related Disease Progression Senolytic drugs are designed to specifically eliminate chronic senescent cells, which could potentially restore treated tissue back to normal function (Figure 12). In pre-clinical animal models, the removal of senescent cells prevented the onset of numerous age-related diseases, including arthritis, cataracts, and kidney dysfunction. Figure 13 depicts an example of an experiment where two mice born in the same litter were monitored for the development of age-related diseases throughout their lifespan. One mouse (left) was allowed to age normally without any pharmacologic intervention, while the second mouse (right) was treated with a senolytic agent to periodically eliminate senescent cells. Interestingly, the mouse on the right receiving the senolytic agent appears visibly younger and did not develop age-related complications despite being the same age as its littermate on the left. \f",
      " 2020 GPS: Global Perspectives & Solutions August 2018 Eliminating senescent cells has been shown pre-clinically to prevent the onset of age- related disease and restore normal tissue function To further support this finding, numerous other high-profile papers conducted in multiple disease models and published in top scientific journals (i.e., Nature, Science) have reached the conclusion that eliminating senescent cells prevents the onset of age-related disease and restores normal tissue function (see Baker, D. J. Nature. 2011 and Chang J. Nature Medicine 2016). One study even found that clearance of senescent cells led to a significant increase (~35%) in median lifespan (Baker, D. J. Nature. 2016). Taken together, we believe the preclinical evidence supporting a role for senescent cells in aging is unusually strong. Senolytic Therapies Have Immense Potential, but Proving Safety in Humans Remains a Key Question Chronic cellular senescence has been associated with aging, but as alluded to above, acute cellular senescence remains an important biological process necessary for cancer surveillance and wound healing. Therefore, the key questions are whether treatment with a senolytic could (1) cause unforeseen adverse effects following the removal of chronic senescent cells and/or (2) disrupt the normal development of acute senescent cells as needed. While clinical data is needed to confirm safety in humans, senolytics have demonstrated remarkably clean safety profiles in preclinical animal models thus far, with no reported adverse effects across numerous studies in separate laboratories. For instance, mice that were treated with a senolytic were observed to have a similar rate of cancer incidence as their untreated counterparts. And senescent cells were found to re-accumulate following the withdrawal of the senolytic treatment, indicating that acute senescent cell development was not disrupted, a key positive for safety. \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 21 t should be noted, however, that following senolytic treatment, wounds healed more slowly in mice compared to untreated counterparts (Baker et al. Nature. 2016). Importantly, the wounds healed correctly and thoroughly, but just took longer to resolve. This indicates that the development of acute senescent cells is only briefly interrupted following senolytic treatment. Nonetheless, to sidestep these concerns, the studies being conducted by Unity (and presumably other senolytic drug developers) will avoid patients who have recently undergone surgery (e.g., the risk of inadequate/slow wound healing following senolytic treatment could render emergency surgery or acute injury hazardous, see Figure 14). We are expecting the first Phase 1 human proof-of-concept data from Unity in the first quarter of 2019 (the trial began in May 2018; Figure 9), and this could place the pre-clinical data on wound-healing risk in better perspective. Another important consideration is the appropriate frequency of dosing with a senolytic. Because the accumulation of senescent cells is thought to occur slowly over months or even years, it is possible that an intermittent dosing approach could be adopted (Figure 14). Therefore, treatments might be administered only once or twice a year, or potentially even less frequently, depending on the target indication. And while speculative ahead of initial clinical data, an infrequent dosing scheduled could limit potential safety concerns. \f",
      " 2222 GPS: Global Perspectives & Solutions August 2018 The success of monoclonal antibodies underscores the significant commercial opportunity in age-related diseases and validates the hypothesis that eliminating senescent cells could prevent disease progression Multi-Billion Dollar Monoclonal Antibody Franchises Could Be Disrupted if Senolytics Come to Market Monoclonal antibody therapies such as Humira and Enbrel (both approved for numerous forms of arthritis and psoriasis) and Eylea and Lucentis (both approved for wet age-related macular degeneration and diabetic retinopathy) have become multi-billion dollar drugs both in the U.S. alone and worldwide (Figure 15 shows U.S. sales for these representative blockbuster antibodies). Importantly, the commercial success of these antibodies is a key validation for companies targeting age-related diseases with anti-aging therapies because (1) these antibody franchises demonstrate the substantial commercial opportunity within these disease areas and (2) the specific targets of many monoclonal antibodies are, interestingly, produced directly by senescent cells across numerous diseased tissues (Coppe J. P. PLoS Bio. 2008). This implies that treatment with a senolytic therapy could potentially eliminate the source of many monoclonal antibody targets that contribute to disease progression. If this turns out to be the case, senolytics could achieve at least the same goals as the aforementioned antibodies, and potentially more as the antibodies only target one factor (vs. a pool of secretory factors that would go away with elimination of the chronic senescent cells). First Senolytic Therapy Could Be Approved by 2023 The first senolytic therapy in clinical trials is a compound by Unity, UBX0101, which is a small-molecule drug that functions by inducing apoptosis (i.e., programed cell death), specifically in senescent cells. The company is first testing UBX0101 locally in patients with moderate osteoarthritis of the knee, which is a substantially large market (~17 million patients). Initial proof-of-concept data from the Phase 1 trial are expected in the first quarter of 2019. If successful in later clinical development through Phase 3, UBX0101 could become commercially available by 2023. While speculative given the novelty of the senolytic therapeutic strategy, a successful therapeutic that could resolve osteoarthritic knees and return knee tissue to a more youthful state could have a negative impact on the knee-replacement surgery market (currently projected to grow to >3 million knee replacements per year by 2030). Because other senolytics are being developed for multiple ophthalmologic (wet AMD, glaucoma, diabetic retinopathy) and pulmonary (COPD, idiopathic pulmonary disease) indications, within the next ~1020 years patients with a range of age-related diseases may experience a decreased need for therapies now considered standard of care. \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 23 Itay Michaeli U.S. Auto and Auto Parts Analyst The Car of the Future promises to address inefficiencies of the Car of Today as well as potentially change personal mobility as we know it The auto market of the future will be a combination of RoboTaxi driverless car services, AV Subscriptions and traditional ownership and EVs will be a critical competitive input in all three areas We expect RoboTaxis to begin U.S. commercialization in 201819\n",
      "\n",
      "4)\n",
      "3. Autonomous Vehicle Networks Driving the Car from a Consumer Product to a Network We believe the looming era of driverless cars will transition the car from a consumer product towards more of a network a network you can access on- demand or as a subscriber. To be sure, this disruption wont necessarily affect every type of car (pickups and large vans are less affected) or every region (rural and snowier regions are less affected), but it will likely redefine large parts of the automotive market, as well as related non-automotive verticals. When thinking about innovations such as artificial intelligence (AI), connectivity, electrification, big data, etc., there is perhaps no more obvious use case than the Car of Today. Todays cars as advanced as theyve become still operate well below their full potential. Consider the significant cost and societal implications incurred from cars not being as safe as they can be, not monetizing data the way they theoretically can, and not being utilized as efficiently as they can. The age of mass-market personal cars solved many problems of the past, but also created new ones congestion and pollution being particularly notable. And vehicle safety, while vastly improved, remains a substantial societal and economic problem thats unfortunately hasnt gotten easier in the age of distracted driving. The Car of the Future which combines advancements in AI, connectivity, computing power, and electrification not only promises to address many of these problems, but will also potentially change personal mobility as we know it. The tipping point for all of this will be the entry of the driverless car (autonomous vehicle AV). Unlike semi- autonomous vehicles (i.e., level-2, or level-3), a fullAV is a vehicle capable of operating without a human driver inside the vehicle. At the end of this transformation, we think the auto market will be characterized by: 1. RoboTaxi driverless car services (mobility-on-demand, or rideshares) operating mainly in urban and some urban/suburban markets. These are dedicated fleets similar to Uber today but utilizing driverless cars. 2. AV Subscriptions, i.e., driverless-capable cars that one subscribes to combining the best attributes of personal ownership with the benefits of AVs, 3. Traditional ownership in certain segments and regions (pickups, commercial vehicles). These traditionally-owned vehicles can still have AV features sold as standalone options, even if they are off the network. Electric vehicles (EVs) will be a critical competitive input in all three of these mobility options, since EVs can reduce the cost of ownership while addressing tailpipe emissions in urban regions (particularly important, in our view, for the RoboTaxi vertical). We see this occurring in a number of stages: Stage 1 (2018+) -RoboTaxi AV as a Network (urban/suburban): A RoboTaxi can be defined as a fleet of driverless vehicles operating rideshare (taxi) services in a particular area, mainly es and surrounding suburbs. We expect RoboTaxis to begin U.S. commercialization in 201819, led by Waymo and GM. The race to launch and commercialize RoboTaxis is all about building a powerful network effect. This network effect is determined by who can introduce and effectively scale safe, reliable, fast, and low-cost urban RoboTaxiAV fleets. \f",
      " 2424 GPS: Global Perspectives & Solutions August 2018 Full highway autonomy will likely be available as an option on cars by 202021 By the mid-2020s, we believe AVs will expand into personally-owned vehicles Heres an example: Suppose a RoboTaxiAV fleet launches with greater human safety in a major city. The absence of driver costs allows that AV fleet to offer a significant price discount to consumers (~40%) vs. conventional rideshare/taxis, while still operating at unit profitability or at least breakeven. Lets also assume the AV is purpose-built to include four compartments for passengers and a few compartments for deliveries. The demand generated by this newAV fleet (initially drawing demand because its cheaper) allows the vehicles to (1) gain further data/driving experience, thereby presumably making the fleet safer and faster (more human-like) through rapid learnings, and (2) pool people and things in safe/private compartments to generate a higher load-factor that reduces the price per mile for consumers. If we assume that this fleet has a one-year head start versus the next competitor, this lead fleet can essentially become safer, faster, and cheaper than its late-arriving competitor. And if we assume the fleet started scaling in a complex domain (major city, many routes) and operating at unit profitability, then scaling to additional es can occur faster than had the fleet started operating somewhere less challenging or less dense. To that, theAV RoboTaxi model is expected to commence in urban areas for a few reasons urban density yields respectable unit economics on initially very costly vehicles (allowing companies to scale up), a low-speed environment enables relatively safer deployment, and es are ideal grounds to improve upon congestion and pollution challenges (we think EVs are clearly advantaged in the RoboTaxi race). Weve previously estimated the U.S. urban/suburban RoboTaxi revenue total addressable market (TAM) to be ~$900 billion. Key U.S. players in this race include Waymo, GM, and Uber. And as noted, the stakes go far beyond the ~$900 billion revenue pool the network effect described above could lead to a few regional winners-take-all outcomes. Stage 2 (2021+) -AV Standalone Features (highway first): Around 202021, we expect to see more AV (level 3+) driving features sold as options similar to how many options are sold today in cars (including through greater use of over- the-air (OTA) updates). Full highway autonomy will likely prove to be a popular and reasonably affordable feature highways tend to be somewhat less complex than urban centers, and who wouldnt want to let the car drive while Features like this exist today at a level-2+ and level-3 basis (Nissan ProPilot, GM SuperCruise, Tesla Autopilot, Audi Traffic Jam Assist), but upgrades to level-4 are expected around 2021. Stage 3 (2023+): AV Subscription Networks (Level 4+): The third stage comes around the mid-2020s and entails expandingAVs into personally-owned vehicles that consumers can purchase, but perhaps more compellingly, subscribe to. The biggest gating factor for personal AVs (relative to urban RoboTaxis) is AV cost optimization and robust crowdsource mapping, in our view. A common misconception we hear about personalAVs is that theyll need to be level-5AVs that can operate anywhere/everywhere. We dont view it this way. We see plenty of compelling level-4 applications, even at the personalAV level. One such example is a human-lessAV thats allowed to operate in driverless-mode only in middle-of-night with no humans, only at reasonably low speeds, and perhaps initially on specific routes. This effective level-4+ domain, in our view, would be sufficient to unlock new and powerful models includingAV Subscriptions and a related subset in peer-to-peer sharing. An AV Subscription would be an effectively leasedAV combining the benefits of ownership (instant access to a car) with sharing optionality (peer-to-peer) and swapping, as well as an arguably far better ownership experience by having service done autonomously at 2am. \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 25 AV Subscription networks for personal AVs should have a simplified payment structure, plus benefits like autonomous service, vehicle swapper, and liquid peer-to-peer loans Benefits from EVs, AVs, and the network effect unlock a significant cost-of-ownership tailwind throughout the life of the vehicle So in addition to traditional car ownership and leasing, automakers would createAV Subscription networks for personal AVs available for sale. Lets assume this vehicle is an EV and that EVs have more/less reached cost parity with ICE vehicles. Lets also assume that the cost of the AV technology comes down to a reasonable $6,000 a figure we think is reasonable based on supplier commentary. A consumer considering a purchase of vehicle XYZ would be offered a subscription to that vehicles EV/AV trim level. Subscribing to that EV/AV would provide the consumer with several benefits: Payment Structure: A simplified monthly payment providing a flat fee to cover the vehicle, insurance, fuel (electricity), and maintenance. Benefits: Besides enjoyingAV features while using them in the car (highway automation), the subscriber would also enjoyAV-related benefits such as the car going in for service (or a car wash) in the middle of the night. Or the car dropping you off and picking you up later to save on parking expenses. Or a car going to pick up merchandise from a store/mall near you in the middle of the night (lastmile delivery). Vehicle swapping: Network subscribers would have the option to swap their vehicles for another vehicle in the network. To ensure constant availability of vehicles, the network (OEM) would always have a small fleet of extra vehicles available at dealer lots an assortment of leisure and utility vehicles that might fit a consumers occasional need/want. This would be an added network convenience feature. Liquid peer-to-peer: Peer-to-peer would allow owners ofAV-equipped vehicles to loan out their vehicles to peers in exchange for a fee, with the transfer of the vehicle occurring in the middle of the night with no humans in the car. We think Teslas planned Tesla Network might end up becoming a peer-to-peer network. So lets say youre not planning on using your car tomorrow; at 2am the car can drive itself to the renter and come back to you the next night at 2am. Peer-topeer might also entail lending your vehicle to that networks RoboTaxi fleet (if one exists), thereby making that RoboTaxi fleet asset-light while creating more liquidity for the subscribers of the AV network. So if the network already has a scaled RoboTaxi business, that extra liquidity might be advantageous to prospective customers considering an AV Subscription. Its important to always note that swapping vehicles would be entirely optional for the subscribers. If you want to have your car for the entire subscription and never swap/share, thats fine. Subscriptions could be tiered based on luxury/mass segments as well as vehicle age. For example, a Platinum subscription would always ensure subscribers receive vehicles that are 04 years old, Gold would ensure 48 years, Silver 812 years, and so on. For each tier, a new fleet of vehicles would arrive every ~4 years. For many, this would eliminate the anxiety of monitoring their cars residual value as a funding source for their next car. Every ~4 years you get access to an incoming fleet. Based on the economics of this model, we estimate that the consumer could end up paying the same or even a bit less (per month) than with a non-AV vehicle. Thats because the benefits of EVs, AVs, and the network effect promise to unlock a significant cost-of-ownership tailwind throughout the life of the vehicle. \f",
      " 2626 GPS: Global Perspectives & Solutions August 2018 Automakers could structure monthly payments that capture the economics of vehicle maintenance, lower insurance costs, and much safer AVs For instance, by taking control of the vehicle throughout its life, the automaker (network) could structure a compelling monthly payment for consumers by capturing the economics of vehicle maintenance that isnt presently captured by the automaker today, while realizing lower insurance costs from much-safer AVs. Some of those savings could be passed on to consumers as part of the monthly subscription cost. By way of brief summary, heres how weve previously modeled it: Assume the network sets its monthly payments (revenue) at the cost-ofownership for a conventional car. For conservatism, we did not include parking costs as a component of vehicle cost of ownership, nor did we assume any revenue priced-in from optional peer-to-peer sharing fees. We assumed the EV/AV vehicle comes at a $6,000 added variable cost versus the conventional car again, were talking about 202325+ so by then the industry benefits from lower-cost sensors (LiDAR), learnings from AV developments (including RoboTaxi players), and next-gen cameras and radars (higher resolution/range) should be evident. We view this as reasonable based on supplier commentary around future level-4+ costs. The network, in this case an automaker, sells the vehicle to a FinCo and leases the vehicle back. We impute the leasing cost of the vehicle over the 15-year life at a $0 salvage value with an interest rate of 3% and a vehicle price of $41,000, which takes the $35,000 price imputed above and adds $6,000 of AV content. EV range at 300 miles on a 70kWh battery at $0.12 electricity cost. Insurance savings = 40% versus a conventional vehicle thanks to theAV sensor suites performing highly-advanced advanced driver-assistance systems (ADAS) at all times. Maintenance costs savings =35% due to lack of aftermarket mark-ups and presumably lower lifetime maintenance cost of an EV. That being said, in year-9 we did assume that the network replaces the EV battery. \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 27 Based on our modelling, we estimate a fleet of 100,000 AV Subscribers can earn $2.5 billion of lifetime gross profit EVs have had market focus of late, but the emphasis on AV Networks is increasing We think market observers are still painting with a broad industry brush and instead should look at individual vehicle segments and regions Looking at AV Subscription as a component of the long-term opportunity is key Total addressable U.S. RoboTaxi revenue market is estimated at $900 billion A fleet of 100,000 AV Subscribers can earn $2.5 billion of lifetime gross profit Based on the above, we roughly estimate a fleet of 100,000AV Subscribers can earn $2.5 billion of lifetime gross profit. This would be in addition to an estimated ~$900 billion RoboTaxi U.S.-revenue total addressable market. More importantly, given the sizable safety, economic, and convenience benefits that such networks could offer consumers, we could see a very rapid acceleration of level-4+ AV vehicle penetration. How Well Is AlthoughAVs are constantly being discussed in press/analyst circles, we think the market remains in the fairly early innings of truly modeling the long-term net implications and the resulting winners and losers, which at times requires local-level (city/county) modeling. Part of this stems from the markets having seemingly spent far greater time focusing on electric vehicles in recent years, no doubt a function of Teslas emergence. AVs were in discussion, but more so from a feature perspective (cars offering semi-autonomous features) as opposed to theAV Network perspective, where the real disruption lies, in our view. To be sure, in the past 68 months AVs have seen greater emphasis on AV Networks thanks to high-profile transactions and other events. But we still see several misconceptions that suggest to us that the net opportunity isnt deeply understood yet: For example: We dont think its commonly recognized that the impact on individual vehicle segments and regions is likely to vary widely. We believe that the most disrupted areas will be sedans in larger es and/or good weather states. Least disrupted are commercial vehicles (pickup trucks/vans) in rural and/or poor weather states. Investing in a world of AVs requires far more local knowledge of individual markets (urban battlegrounds), as opposed to the more traditional country/continent analytical approach. We think market observers still paint the industry in broad strokes (all XYZ companies will be) as opposed to focusing on detailed segment and regional analysis. We think this will change as RoboTaxis commercialize. Recent investor attention has focused on the Robotaxi (mobility-as-a-service) industry. To be sure, weve written about RoboTaxis for years and view them as a very sizable component of theAV Network disruption. But its just the start we dont think theres nearly enough emphasis on the AV Subscription component of the long-term opportunity. Again, the common reaction tends to paint very broad outcomes all consumers will cease to own cars everywhere (at times contradicting one of the biggest bull cases for EVs, which is the fun-to-drive factor) as opposed to breaking down the impact in city vs. rural, individual vehicle segments, and how networks can combine the value of owning with the value of sharing/subscribing.All of this carries major investing implications. We estimate the U.S. RoboTaxi addressable revenue market at $900 billion, or ~$0.60 per mile on ~1.5 trillion urban/suburban miles driven (representing ~50% of all U.S. miles driven). The network-effect element described above suggests that this will be a few-regional-winners-take-all market. The AV Subscription market is also sizable particularly when considering the potential historic transfer of wealth in the automotive supply chain arguably from the rental car and aftermarket revenue channels into the AV network. As noted previously, we roughly estimate a fleet of 100,000 AV Subscribers can earn $2.5 billion of lifetime gross profit. \f",
      " 2828 GPS: Global Perspectives & Solutions August 2018 If AVs brought household vehicle density down from 2.2x to 1.0x, there would be a drastic 54% reduction in the number of cars on the road The disruption is a change of the delivery of mobility from a product to more of a network Defensive attributes include exposure to rural areas, commercial vehicles, and snow- heavy states. Offensive attributes include strong AV technology and a clear AV business plan Lets do some back-of-the-envelope math: Today, an automaker might earn $8,500 of variable profit per unit sold, and then lets say another $1,500 from follow-on services etc. The U.S. light vehicle population stands at 272 million, meaning that an automakers lifetime vehicle profit TAM is $2.7 trillion. Now lets assume that AVs eventually bring down household vehicle density to 1.0x from 2.2x today a drastic move that would see a 54% reduction in the number of cars on the road. To be sure, outside of urban RoboTaxis affecting personally-owned car ownership in es and close surrounding suburbs, we dont think that the remainingAV business models (AV Subscribers) would necessarily lead to a substantially reduced vehicle- density outcome, due to the value of having instant access to mobility. Our prior modeling has shown a ~12% decline in future U.S. demand (new vehicle sales) by 2030E. Nonetheless, going with the 54% decline for a moment would mean that we have 126 million light vehicles on the road. Our AV Subscription math previously showed a lifetime adjusted gross profit of $29,000 per vehicle, which would amount to $3.7 trillion on 126 million vehicles on the road. This suggests that the total lifetime profit pool actually rises by >30%. So the disruption isnt necessarily about an auto industry going away or even shrinking (quite the opposite), but rather a drastic change of the delivery of mobility from a product to more of a network and all the resulting changes in supply-chain economics, winners and losers within the auto industry itself, and the impact to existing industry stakeholders. The AV technology itself is rapidly improving toward a likely commercialization in certain domains (geo-fenced zones, speeds, weather conditions) in a matter of months as opposed to years. When it comes to adoption barriers, rather, we tend to think of consumer acceptance and regulations. Inevitably, things do and will go wrong and unfortunately tragedies and mistakes do occur. To be sure, we view such risks more as setback potential than a question; the latter we believe has already become fairly inevitable. To be sure, human-driven cars andAVs will coexist for a long time to come, even with a rapid scaling of RoboTaxi and eventualAV Subscriptions. Of course, the investment communitys perception of winners/losers might change rapidly, well beforeAVs scale to higher volumes (similar to what weve seen with the EV theme), once theAV end-game becomes more apparent to the broad investment community. On the automaker side, we consider defensive & offensive attributes. Desired defensive attributes include having greater exposure to rural areas, commercial vehicles (pickups vans), and snow-heavy states. If you can find all three, thats a good start. Offensive qualities include having strongAV technology and a clear AV business plan that considers all of the important network and product aspects discussed earlier. For example, for RoboTaxis the AV tech is of course most important, but nearly as important is the vehicle itself EVs will be advantaged and purpose-built likely superior to retrofits, and their ability to scale efficiently will be an advantage: servicing, fleet management, cybersecurity etc. For AV Subscriptions, advantages will extend to having a full line of vehicles for swapping, a liquid dealer network for peer-to-peer management, and robust connectivity/security. Therefore, we look for companies that bring both defensive and offensive qualities to the table. \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 29 For auto suppliers, we look for companies who can sell more content on AVs. For auto suppliers, we look for companies that can sell more content on AVs. This would include the AV technology suite itself to the vehicle electrical architecture, cockpit electronics, and other experience-related content (seats, displays). The potentially dramatic shift in industry dynamics and profit pools is also bound to affect stakeholder industries to automotive: How will the traditional rental car industry respond to potential competition from AV peer-to-peer (sourcing cars from How will the auto aftermarket respond if AV Networks attempt to take back If personalAVs can do last-mile delivery to your home, how does that affect freight and retail Who benefits from unlocking time spent in Real estate in general if living near a city becomes less of an advantage thanks to reduced traffic or AV commuter cars being able to travel faster (admittedly this is a longer-term \f",
      " 3030 GPS: Global Perspectives & Solutions August 2018 Stephanie Demko, CFA U.S. Healthcare Technology Analyst The HITECH Act provided financial incentives for provider adoption of EHRs With adoption nearly universal, driving actionable insights from the information captured is key\n",
      "\n",
      "5)\n",
      "4. Big Data & Healthcare Electronification Begets the So What Question The electronic health record initiative and increasing consumer buy-in on wearables has turned healthcare into a data problem. In 2013, at the onset of Meaningful Use, approximately 153 exabytes of healthcare data were produced. Looking forward to 2020, more than 2,310 exabytes of healthcare data are projected to be produced, creating a broad playing field for opportunities in these robust data sets. At the same time, rising costs in healthcare (~18% of GDP), an aging population, and the shortage of clinicians all create a need to monetize this data and bend the cost curve. We view opportunities in big data, artificial intelligence, and machine learning as the natural progression of healthcares newly formed data stores. McKinsey estimates these innovations could reduce healthcare spend by $300$450 billion. We explore the evolution of this trend, existing/potential future applications, barriers to adoption, and the winners/losers below. The Evolution of Data in Healthcare Although Electronic Health Records (EHRs) existed prior to 2009, the majority of EHR sector growth was spurred by government intervention, with an approximately 60 point uptick in penetration rates from the HITECH (Health Information Technology for Economic and Clinical Health) Acts Meaningful Use program. The HITECHAct created financial incentives for provider adoption of EHRs, with the hope that electronifying healthcare data would help bend the ever-growing cost curve for healthcare spend in the United States. In effect, you cant manage what you cant measure so the first step from the government was a mandated measurement rollout. With EHR adoption now nearly universal (96% of hospitals and 87% of physicians reported usage of a certified EHR in 2015, as shown in Figure 17 and Figure 18), we believe it is time to manage costs by driving actionable insights from the information captured. This desire is two pronged: Beyond the government objective of managing healthcare costs, clinicians are also looking to justify the value of these newly-electronified systems given high install/ownership cost. \f",
      " 3131 August 2018 GPS: Global Perspectives & Solutions Big data solutions are the next logical step to utilize the vast data pools Early data applications include analytics and population health as well as applications around patient and supply chain cost With these data stores now created, we believe big data solutions are the next logical step as a way to utilize these vast data pools, similar to what weve seen across other enterprise verticals. From a payer/provider standpoint, big data solutions also create a monetization opportunity in predictive analytics, improved diagnoses, and cost reduction. Early Data Applications in Analytics We are currently in the first wave of healthcare data utilization, with the healthcare information technology (IT) players cross-selling value-added solutions (often driven by their data stores) into their client bases. On the data-driven side, these solutions tend toward analytics and population health. Population health, or pop health, solutions entail quality/cost monitoring and management tools and all that goes with it, including data cleanup, care coordination, patient communication/engagement, and patient education. Pop health solutions can also include rudimentary predictive analytics tools, such as the evolution of a patient along the risk curve, but these tools tend to be early days compared with enterprise-facing big-data solutions. Specialized analytics applications, particularly around patient and supply chain cost, have been another key use of the new healthcare data stores. Unlike the predictive enterprise big-data analytics solutions today, these applications tend to be more backward-looking to help healthcare providers monitor and manage trends. \f",
      " 3232 GPS: Global Perspectives & Solutions August 2018 Defining: Big Data, AI, ML Big Data: Big data is a term that describes a large volume of data both structured and unstructured that traditional data vendors were unable to process. Today, big data refers to the use of predictive analytics to extract value from data. Artificial Intelligence: AI is the concept of machines being able to carry out tasks in a way that we would consider smart Machine Learning: ML is a current application of AI based around the idea that we should be able to give machines access to data and let them learn for themselves The first wave of clinical support applications will help doctors make more robust data- driven decisions in patient treatment A big data solution for interpreting a large store of x-rays can also function as a search engine for the diagnosis Machine-learning apps can leverage data across silos to increase the identification of disease risk Looking Forward: Big Data, Artificial Intelligence and Machine Learning Data Are Core to Healthcare; Big Data Are an Accelerator At their core, medical discoveries are often made by (1) observing associations, (2) creating hypotheses from these associations, and (3) hypothesis testing through clinical trials and real-world applications. We do not view big-data applications as a fundamental change to healthcare, but rather, an accelerator to this process. Given the vast stores of electronic data that have been created, this process can theoretically be fast-tracked through back- testing large data sets. Opportunities from this process acceleration include more robust disease detection tools, predictive diagnosis capabilities, and decision support tools. Near Term Opportunity: Clinical Decision Support While we view predictive diagnosis as the Holy Grail solution for big data in healthcare, we expect this to be a longer-term opportunity given its layers of complexity. In the near to medium term, we see greater viability in decision support tools and, in certain applications, early disease detection. Clinical decision support tools entail any solution that provides clinicians with intelligently filtered patient-specific data at the appropriate time in the point of care to enhance decision-making in the clinical workflow. Ultimately, the first wave of clinical decision support applications will transform patient data from a pull to a push function at the point of care, helping doctors make more-robust data-driven decisions in patient treatment. Current Use Cases While we believe we are still in the early inning of widespread big-data applications within healthcare, some solutions are already in use today. We document a few of these use cases below. Radiology/Medical Imaging Certain functions in healthcare, like radiologists, are considered good once they have a certain level of experience seeing cases. However, a human can never see as many cases as an electronic database, making this an ideal application for big data/AI. Given a large enough store of electronified x-rays, the interpretation of an x-ray becomes a search problem, with a big-data solution functioning as a search engine for the diagnosis. Predictive Risk from Retinal Imaging The retina offers a snapshot of a patients vascular system, but the data are often under-utilized as they are siloed within ophthalmology practice EHRs. Recent machine-learning applications have leveraged this information to predict the risk of heart disease, with early trials showing a higher accuracy rating than the trials clinician evaluations. Although this solution has yet to be used in a clinical setting, we view this as a near-term opportunity that will create a quicker, easier, and lower- friction (no blood test required) solution for evaluating a patients cardiovascular risk. \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 33 Cost reduction within the payments integrity and cost processing verticals is helped by machine learning and natural language processing Predictive analytics models can highlight issues such as transportation barriers that could lead to missed appointments Data siloing and usability issues within the healthcare sector as well as a slower shift to the cloud are potential barriers to quick adoption Claims Processing Early applications of machine learning and natural language processing are currently being used to reduce cost within the payments integrity and claims processing vertical. Traditional claims processing is a labor-intensive solution, entailing a clinician reviewing a complex claims document that often encompasses dozens of pages. With the use of robotic process automation (RPA) and natural language processing (NLP), payers are able to highlight the areas of significance within the claims document and increase the findings rate for errors without increasing headcount. Care Management Support Barriers in healthcare can extend beyond the core condition and treatment, such as access to care, transportation, and readmissions risk. Transportation is one of the largest barriers to care: low-income, elderly, and disabled patients miss ~24 million appointments annually due to insufficient access to transportation. Further, no-show appointments due to transportation barriers alone represent ~$40 billion in avoidable downstream costs and ~$4 billion in lost revenue for doctors. Today, predictive analytics models can highlight patients at a higher risk of encountering transportation barriers by utilizing a patients socioeconomic data. For example, socioeconomic data might show that patients in a certain zip code are unlikely to have a car, alerting the care team to make arrangements for follow-up appointment transportation following a discharge, thus lowering downstream costs. Reducing readmissions is another focus of care management support teams, with predictive models aiding in the allocation of people, process, and technology resources. Beyond allocation, these predictive analytics can also assist a care team in time management, such as the frequency and intensity of follow-ups based on a patients projected degree of risk. Barriers to Adoption Looking at the Enterprise, Its a Long Road Ahead Healthcare IT has historically mirrored the enterprise IT sector, albeit on a multi-year lag. Because of this, we look to the evolution of big data within the enterprise sector to frame our outlook for big-data adoption in healthcare. The rise of enterprise big data has gained momentum in recent years given the elasticity of the cloud and the dramatic reduction of computing and storage costs paired with significant gains in processing power. However, this opportunity in itself is still in the very early innings, with a significant focus on data cleanup and usability. This suggests a long road ahead for big data to truly penetrate the healthcare sector given similar data siloing/usability issues within the healthcare sector as well as a slower shift to the cloud. Additionally, healthcare IT faces several roadblocks that are unique to the space, given the competitive dynamics between the holders (and often times, vendors) of healthcare data. While in the near term, one of the biggest opportunities in enterprise big data is the consolidation/preparation of data for consumption by artificial intelligence and machine learning, this may get pushed off by healthcare IT vendors that are sensitive around releasing their data, which they view as key to their value. \f",
      " 3434 GPS: Global Perspectives & Solutions August 2018 Biggest roadblocks for widespread use of big data include lack of data standardization, siloing, lack of accessibility, the need for a clinical data warehouse, and privacy/security concerns The Evolution of Data Models 1970s: The relational model (rows/columns) for data systems was introduced 1980s: Data warehousing emerges 1990s: Databases move off the mainframe into client / server models 2000s: Rapid growth in data volume pushes traditional data vendors to the limit, creating the need for big-data technology and non- relational databases Aggregation of data siloed across multiple verticals is a barrier Data Presents the Biggest Challenge As Eric Schmidt, former Executive Chairman of Google, noted in his 2018 HIMSS (Healthcare Information and Management Systems Society Conference) conference speech this past March, several steps are required in order for providers and healthcare IT vendors to make use of their newly electronified data. To pave a path to improved healthcare cost/outcomes, vendors need to (1) move healthcare data stores to the cloud, (2) de-silo the data to create robust data sets, and (3) ultimately apply machine-learning models to improve predictive analytics and diagnoses. Echoing Schmidts keynote, we believe the biggest roadblocks facing widespread use of big data for artificial intelligent/machine learning applications are (1) lack of data standardization, (2) the current siloing of medical data, (3) lack of accessibility, (4) need for a clinical data warehouse, and (5) privacy and security concerns. Data Issue 1: Cleanup The lack of standardization across healthcare data presents the largest initial challenge to adopting big-data solutions. The vast amount of data generated and collected by a multitude of agents in healthcare today come in many different forms, both structured and unstructured from insurance claims to physician notes within the medical record, images from patient scans, conversations about health in social media, and information from wearables and other monitoring devices. For the most part, we believe healthcare data are compiled in SQL-based relational databases because these are well suited for discretely codified billing and clinical transactions data. However, this format presents limitations in both the volume and the velocity of data processing, while rapid growth in unstructured health data could create the need for hybrid (relational and NoSQL) databases. Further, the data-collecting community is equally heterogeneous, making the extraction and integration of the data a real challenge. Providers, payers, employers, disease-management companies, wellness facilities and programs, personalized-genetic-testing companies, social media, and patients themselves all collect data. Even standardizing for end market and form, the data standards presented in Meaningful Use were more open to interpretation than a standardized protocol, creating a lack of standardization even across EHR systems. Integration of data will require collaboration and leadership from both the public and private sectors. Data Issue 2: Siloing Medical data are spread across many sources governed by different states, hospitals, and administrative departments and information silos exist across both private and public sectors. Even within organizations themselves, multiple sources of data such as clinical, financial, and operational data are kept separated. The issue is further compounded by each data systems unique key identifiers, validation rules, and format. With medical data siloed in a multitude of verticals, the result is difficulty in data aggregation when attempting to create a complete data set to analyze a patient or a population. The integration of these data sources would require developing a new infrastructure where all data providers collaborate with each other. \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 35 Data sharing and accessibility is limited FHIR creates a standard for different data elements to build APIs for use on datasets from different systems Finding a place to warehouse the huge amount of data in healthcare is a challenge Safeguarding data is key and heightens the cost of data vs. other industries Data Issue 3: Accessibility Stemming from the siloing of medical data, the ability to create full data sets for one patient or a population to work with is limited by the lack of accessibility across different source of data.According to an athenahealth survey, while 79% of doctors believe that having all available patient data in one place is critical to their jobs, only 14% could access EMR information across different departments, patient care centers, etc., even within the same hospital. While recent regulation looks to improve upon data sharing, our channel checks have shown vendor hesitation and proactive friction in data sharing. In order to increase interoperability among hospitals, physicians, and other relevant parties, the industry is slowly shifting to a new technology known as FHIR (Faster Healthcare Interoperability Resources). FHIR creates standards for different data elements so that developers can build application programming interfaces (APIs) that can be used to access datasets from different systems. Data Issue 4: Warehousing Assuming the data get standardized and become de-siloed and accessible for use, the challenge standing in the way is the need for a clinical data warehouse to host the vast amount of data (projected data size 2,310 exabytes by 2020). Only once this data are curated into usable data sets can they then be used for sophisticated analysis with a richAPI. The data warehouse would require two tiers of data, with the first tier being primary data stores sourced from EHRs, supplemented by a second tier comprising unstructured data collected from everywhere else. Data Issue 5: Privacy/Security Given the enormity of total population medical data both in value and volume, large data stores are at a high risk of tampering and theft. This is particularly vital as a leak of identified health data is irreversible, unlike the leaking of a more dynamic data asset such as a consumers credit card information. This security risk necessitates significant investments to safeguard the data, creating a heightened level of cost compared with other industries. Privacy concerns have also led to slower momentum in data storage evolution, with locally hosted systems still prevalent within healthcare due to perceived cloud risk. \f",
      " 3636 GPS: Global Perspectives & Solutions August 2018 Winners and Losers Winners: Big Data Vendors, Healthcare Data Owners We segment the winners of big data in healthcare into two core groupings: the providers of the big data solutions, and the players that own the healthcare data (shown in Figure 19). On the big-data provider side, winners will include the established technology players, the big data vendors, and the existing healthcare ITplayers that take a forward-looking approach to big-data, machine-learning, and artificial intelligence solutions development. These vendors will benefit from selling solutions into both healthcare providers and the existing healthcare IT vendors that are looking to bolster their solution sets via outsourced R&D. On the healthcare-data owners side, we view the most likely winners as the existing EHR players and, potentially, large cloud-computing entrants from the technology side. We believe the data stores created by the EHR players are not only the most comprehensive but that they will be difficult to replicate given their creation via government intervention. Regarding the large cloud-computing entrants, we have seen a greater push by these players to enter the healthcare vertical, creating large de-siloed stores of data. These players will be the best positioned to create saleable solutions from their data stores as well as in selling de-identified data to solutions vendors in need of a robust data set. Losers: Less Impact, Pressure on Manual Processes As big data applications, and even healthcare IT itself, are both newly created fields, displacement risks from this trend are more narrow. Near term, big-data, machine-learning, and artificial intelligence solutions could create downward pressure on pockets of employment in the medical field, such as radiology and claims processing analysts. However, given the intersection of increasing life expectancy and the declining supply of doctors, we believe these solutions are more likely to supplement than displace clinicians. We view these tools as a way to improve clinician productivity, especially in the early days of predictive analytics: Big data solutions will be viewed as decision support, if not the ultimate decision maker. \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 37 Dalibor Vavruska Global Head of Digital Connectivity Strategy and Head of CEEMEA Telecom Research Technologies may eventually reduce the need for exclusive spectrum licensing There are both private and shared assets in market economies As part of creating the design-made wireless industry some spectrum was transferred from a shared public asset into exclusive ownership by wireless companies\n",
      "\n",
      "6)\n",
      "5. Dynamic Spectrum Access Potential Airbnb/Uber Style Disruption in the $1 Trillion Wireless Industry All wireless communications services use electromagnetic radiation from a simple TV remote or cellular phone up to a satellite. For wireless transmission to work, the transmitter and receiver need to be tuned to the same frequency, and no other device should use close-by frequencies (spectrum band) at a particular point in time and space. Otherwise a clash, also called interference, occurs. Spectrum by default belongs to national governments. While some spectrum bands, such as those used for WiFi, are free to be used by anyone, to avoid the possibility of interference between different users of the same band, some spectrum bands are allocated exclusively. Such a framework creates a small group of entities exclusively licensed to use spectrum on a nationwide basis. This is similar to having a small number of hotels or taxi companies exclusively licensed to operate in a particular city. The rationale for such exclusive licensing usually includes security and reliability of service. Innovative technologies like those used by Airbnb and Uber address some of the security and reliability challenges and in turn are able to disrupt the licensed businesses model, possibly making it obsolete. Interference, and hence security and reliability, in wireless communications depend on a range of factors including the power and density of transmitters, frequency bands, landscape, and the design of buildings. Dynamic Spectrum Access (DSA), also known as Dynamic Spectrum Management (DSM), is a technology-empowered framework with the potential to address these complex factors. It allows multiple users to share a particular countrywide spectrum band, ideally in a secure and reliable way. This boosts the efficiency of spectrum utilization and opens wireless opportunities to larger number of players, possibly similar to Airbnb property owners and Uber drivers. Paradox of the Wireless Industrys Design In market economies, there are two groups of assets: private assets that are privately controlled, ideally unregulated, and tradeable (e.g., commodities, properties, consumer products and intellectual rights), and shared assets which are often publicly controlled and heavily regulated (e.g., roads, airports, electricity networks, armed forces, and in the future perhaps certain technology platforms). We see shared assets as being sensible in three cases. The first is for natural monopolies that are prone to sharing, with practically unlimited capacity and adverse consequences if there is duplication, e.g. roads or armed forces. The second is linked to universal service, e.g., the need to connect all homes to an electricity network of a certain standard. The third is linked to industrial policies, which intentionally suppress or fail to encourage local competition in specific areas to build national advantages in global competition, e.g. infrastructure and technology platforms. The emergence of mass-market wireless technologies has led people to question how spectrum should be treated. Historically, spectrum was a shared asset used by public services such as radio, TV, security, or anybody else in unlicensed bands (used today for example for WiFi). Later on, as part of the creation of the wireless industry, some spectrum was set aside, divided into a small number of pan-national exclusively-licensed bands with long-term validity, often with prescribed technology, type of service, and agreed territorial coverage. This spectrum was then exclusively awarded to future wireless operators. \f",
      " 3838 GPS: Global Perspectives & Solutions August 2018 but can the wireless industry, with its privileged access to spectrum, now be falling victim to its own success and hitting Questions about network and spectrum sharing are increasingly pertinent in the context of IoT and 5G DSA uses advanced technologies to boost efficiency of spectrum utilization by enabling spectrum-sharing among multiple users To encourage capital inflow into this new industry, policymakers chose to treat wireless as a competitive industry and refrained from major regulations. Unlike the technology industry, which usually evolves spontaneously around innovative ideas, the wireless industry was basically design-made by policy-makers as part of their effort to build territorial wireless coverage and deliver specific services (e.g., voice and messaging) as fast as possible. The wireless industry has undoubtedly been successful in fulfilling its objectives. The vast majority of the worlds population now benefits from mobile coverage (there are currently 5.2 billion unique mobile users, equal to 70% of the worlds population), and data speeds are continuously rising. However, unless the wireless industry can develop new major technology and service-driven growth opportunities (we call them DIGITECCS: Digital Technology, Connectivity and Service), it may in our view fall victim to its own success, by simply fulfilling the objectives it was created for. The design-made nature of the wireless industry is increasingly leading to the need for non-systemic regulatory interventions that tackle oligopolies, coverage/quality issues, and the inefficient use of spectrum. This raises the question about the benefits of the currently-established spectrum ownership privileges of a specific industry with a specific business model. In a June 2018 : SouthAfrica, 5G, DSA and DIGITECCS inspired debate about wireless we highlighted three key opportunities for wireless expansion: (1) uncovered areas, (2) areas with low-quality coverage, and (3) the use of small cells for industrial innovation. It is not particularly clear to us that the existing model of multiple competing nationwide wireless networks, as leading spectrum owners, is best suited to address any of these. It may appear that designers of the wireless industry wanted to square the circle by creating a private unregulated industry to provide what is increasingly turning into a public service with extensive government-prescribed coverage and quality targets and obligations. It also appears that the providers of this service may at least in some areas benefit from the concept of asset sharing (due to, for example, natural monopolies in passive infrastructure, desirability of some form of universal service, and industrial policy interests in security and infrastructure investments for the digital economy). Hence, questions about whether spectrum and networks should be shared, and to what degree, remain relevant, especially since wireless growth is becoming scarcer and 5G/IoT is prompting the need for a policy re-think. What Is DSA and How Can It As we already discussed, spectrum is a finite resource, the sharing of which may cause interference challenges and ultimately degrade the wireless connection quality. This is why certain bands are exclusively assigned to the wireless operators nationwide. However, these exclusive spectrum users have a natural economic incentive to utilize their spectrum more efficiently in areas that are more economically attractive than others. Meanwhile, other (potentially more innovative) users may not have access to spectrum at all, even in areas where it is not utilized by the exclusive owners. In addition, some spectrum cannot be utilized because of its sporadic use by government institutions, for example by the armed forces. DSA is a technology-empowered framework designed to address these challenges by using innovative ways of sharing spectrum bands among multiple users, based on technologies such as software, game theory, machine learning, and artificial intelligence (AI). DSA may offer the following capabilities: \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 39 1. Dynamic spectrum re-allocation between users: Spectrum in specific locations and time points can be flexibly allocated using a tiered system where spectrum holders are assigned priorities as opposed to exclusivity to use spectrum. Spectrum can be flexibly reallocated to a diverse set of entities, which avoid collision by knowing each others needs and flexibly managing channels (cognitive radio) and transmission power. 2. Use of imperfect (not entirely interference-clean) spectrum channels: Software-based technologies exist, which could increase reliability and data throughput of imperfect channels by mitigating interference-related imperfections. These technologies are well known to the telecom industry, because they are widely used to prop up performance of copper-based fixed- line channels, e.g., vectoring and G.fast. In theory, similar solutions could be deployed in wireless as well. Should the wireless industry brace itself for So far, DSAhas been primarily focused on utilizing underutilized and sporadically DSA-driven Airbnb-and Uber-style used spectrum and in the cleanup of interference but not necessarily in disruptive ways. Wireless operators could in fact benefit from DSA, which gives them an opportunity to acquire priority access to more spectrum in specific territories. However, we think that DSA can also strengthen momentum behind regional, community, municipal, and corporate wireless networks, which have so far been operated on unlicensedWiFi spectrum. This may disrupt the wireless industry in the following ways: 1. Creation of a shared wireless economy: Technological progress has led to the emergence of shared economies in areas such as accommodation and transportation. By making spectrum more widely available, DSA could fragment the wireless market and possibly lead to similar opportunities. This could create shared economies with multiple providers of connectivity (accessing spectrum through DSA and connecting radio antennas, for example, to national fiber networks, similar to the use of public roads by Uber cars or water supply in Airbnb properties) and multiple users (e.g., people with devices, which allow connecting to such networks). The phenomenon of small localized networks is not new in telecoms; examples range from metropolitan WiFi to local fiber networks. DSAcould, however, give these networks key attributes that they have been missing so far: spectrum, and subsequently compatibility with the mainstream wireless technology such as 4G and 5G. 2. Changes in regulation to limit availability of nationwide exclusive spectrum: DSA opportunities raise two crucial questions for the policymakers. (a) Should low-frequency bands occupied by non-telecom users such as TV also be (b) Should frequency bands, particularly those above 3.5GHz where blanket nationwide coverage is impractical, be allocated on a DSA-priority basis instead of an exclusivity If the DSA technology proves reliable, it would be hard to argue against these suggestions. However, if these concepts are adopted, the wireless industry may over time lose its privilege to use crucial spectrum exclusively, i.e., it may no longer be able to prevent disruption by withholding access to spectrum from potential disruptors. \f",
      " 4040 GPS: Global Perspectives & Solutions August 2018 The first major DSA project, CBRS, is currently under way in the U.S. 3. Creation of an alternative model for 5G small-cell deployments: Wireless operators usually see 5G/IoT small cells (operator-controlled low-powered mobile base stations) as their crucial growth opportunity. We see commercial small-cell opportunities first emerging in industrial innovation (e.g., coverage of production plants) and services (e.g., coverage of airports, hotels, entertainment parks, etc.) Purpose-built networks accessing spectrum via DSA (as opposed to parallel competing networks using exclusive countrywide spectrum) would seem sensible in many cases. These networks may be built by industrial or service companies, tech companies, and small/medium enterprises as a 4G/5G-compatible upgrade of WiFi-based solutions. Even though owners of such networks may have to respect priority rights of other users to their spectrum, in practice this constraint may be manageable, because we are often talking about short-range indoor installations. Priority users may often not even have physical access to these indoor areas. In an extreme case, the wireless market may re-shape toward territorially fragmented, localized high-capacity networks with relatively high efficiency of spectrum utilization under DSA. Meanwhile, nationwide coverage, for example for voice, Internet access, and secured data services, may eventually lean toward a public service using nationwide spectrum. 4. Dilution of some of the unique skills of wireless operators: Good wireless operators usually stand out in two areas: (a) their ability to acquire spectrum so that the benefits of owning it outweigh its costs and related obligations as much as possible and (b) their ability to build networks, i.e., add sites at the right pace and to the right locations to maximize returns. DSA may bring more transparency and fragmentation to the spectrum markets and hence reduce potential advantages of specific operators. Moreover, it is possible that the tech industry may gain quality big-data on subscriber locations, geographies etc., which together withAI may allow it to develop network planning skills and similar toAirbnb or Uber manage networks with capacity provided by a large number of smaller entities. The tech industry has already been involved in several attempts to dilute the unique nature of the wireless industrys skills. This involves, for example, localWiFi networks, WiMax, soft SIMs, or mobile virtual network operators (MVNOs). None of this, however, has led to major breakthroughs. This may be because opportunities for the to-be-disruptors may not have been big enough for them to invest sufficient amounts of energy or due to the practical obstacles. In the future, 5G/IoT may bring the opportunities while DSA could help overcome some of the obstacles. How Close Is DSAto The DSA concept has been known for years, but a number of barriers have so far delayed major deployments. The technology still needs to go a long way to prove its ability to significantly have an impact on global Technology, Media & Telecom (TMT) markets.According to the Dynamic Spectrum Alliance, there are currently several dozen DSA-localized deployments spread over all major continents, mostly using TV white space (spectrum allocated for TV broadcast, but practically unused in some bands and territories) for local broadband. Taking this to the next level, the CBRS (zens Broadband Radio Service) shared-spectrum scheme is currently being introduced in the United States. It is meant to be suitable for LTE phones, indoor coverage, and small cells. The scheme will initially operate on a 150MHz block in the 3.5GHz band, using DSA to create a priority-based system for multiple users of the same spectrum (also see transcript of our interview with CEO of Federated Wireless, which is involved in this project: Federated Wireless Conference Call: Call Transcript and Replay Details from April 2018). \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 41 CBRS is a priority-driven scheme, which allows multiple users to access the same spectrum bands DSA is a global story for years to come, but potency of the technology, backing by the big tech industry, and the need for a policy re-think ahead of 5G are already making it strategically relevant Potential of DSA is not yet widely recognized The first priority to the CBRS spectrum will go to the original users such as the Navy. Subsequently, other entities could buy second-p0riority access to some of this spectrum in PriorityAccess License (PAL) auctions. Finally, spectrum left vacant by the second priority users is open to a broader range of users. CBRS is expected to help in fixed-wireless access and densification of the wireless networks, but also in a variety of new use cases such as indoor small cells in buildings, in public spaces, and in industrial premises (for IoT). Due to the relatively short range of small cells it may not be practical for priority users to perform physical deployments in many areas, leaving this opportunity under DSAto other parties. The scheme is expected to be operational late this year or early next year. The success of CBRS is in our view crucial for further spread of the technology globally. Practically, it may take years for DSA to more significantly influence the way spectrum is allocated or managed around the world. However, we see the following grounds to believe that DSA may be already strategically relevant: Theoretical potential of DSA: In the 5G/IoT environment and digital economies, importance of spectrum is likely to rise. DSA can theoretically lead to substantial improvements in spectrum utilization in three ways. Firstly, by allowing multiple users to use the same spectrum by managing to avoid interference. Secondly, by fragmenting and hence boosting the competitive efficiency of the wireless markets. Thirdly, in the longer term, by deploying technologies to boost performance even with some channel interference. In addition, DSA allows the use of spectrum without an expensive cleaning process, i.e., without covering the cost of equipment, for example, for military users. Finally, a significant part of industrial connectivity innovation has so far been taking place on WLAN (WiFi) as opposed to the wireless operators networks. DSAhas the potential to further expand such innovation. Tech industrys backing: The CBRS ecosystem was originally founded by companies such as Qualcomm, Nokia, Ericsson, Intel, Google, and Federated Wireless. The Dynamic Spectrum Alliance is currently backed by a number of tech companies including Google, Amazon (joined in June 2018), Microsoft, and Facebook. We think that success of DSA is reasonably strategically important for the tech industry, because it would increase the available bandwidth (hence potential use of software/tech products) and create opportunities for tech companies to manage spectrum allocation, but also reduce the ability of the wireless companies to act as gatekeepers. Given the high valuations and recent stock market volatility in tech, we think that DSA is likely to become even more pertinent for the tech industry, Need to review spectrum allocation policies ahead of 5G: Finally, spectrum allocation debates, particularly in high frequency bands for 5G small-cell coverage, will become highly relevant in the coming years. If the DSA arguments gain momentum, the technology may disrupt the wireless industry even before the completion of large-scale rollouts, simply by limiting the wireless industrys ability to acquire spectrum exclusively. How Well Known Our recent conversations with telecom operators and investors show that DSA is not yet widely known and understood by the market. While investors awareness of the technology is relatively low, wireless operators know it, but with the possible exception of those in the U.S. they do not yet see it as material in their strategic planning. That said, some open-minded regulators including the FCC (U.S.), Ofcom (U.K.), and ICASA (SouthAfrica) have been pursuing DSA related opportunities. \f",
      " 4242 GPS: Global Perspectives & Solutions August 2018 The ultimate aim of DSA spectrum abundance may have an impact on wireless and spectrum assets worth trillions of dollars in the course of boosting the digital economy DSA should lower the cost of wireless connectivity and boost innovation Restraining the wireless industrys spectrum privileges would be a major policy move and would naturally attract opposition Spectrum is the key asset of the global wireless industry, whose revenue is in the range of $1 trillion, meaning the enterprise value of the worlds wireless operators can be estimated in the single trillions of dollars. The U.S., which accounts for nearly a quarter of the global economy, generates more than $200 billion in wireless revenue. The total value of licensed spectrum in the U.S. is around $0.5 trillion (source CTIA 2015, adjusted), indicating that all spectrum may be worth trillions of dollars globally. This spectrum value is naturally driven by supply, demand (how it is used), the conditions under which it is awarded, etc. The ultimate aim around DSA, spectrum abundance, may affect the global wireless industry by reducing entry barriers to owning spectrum and inviting new companies into the market.As a result, some spectrum value may shift away from the taxpayer (governments charging for spectrum) and the wireless operators (owners of spectrum) toward the broader economy (including business users) and the tech industry. Estimating DSAs disruptive effect on the wireless industry and its broader positive economic benefits is difficult at this early stage, although the Dynamic Spectrum Alliance, for example, shows a $0.5 trillion estimate of economic surplus of the U.S. unlicensed (WiFi) spectrum today. DSA is likely to gain momentum especially if it proves its reliability and shows its broader economic benefits outweigh its costs and disruptive effects. We see its economic benefits in the following categories. Lowering of costs and boosting capacity of wireless connectivity by (a) utilizing heavily underutilized spectrum currently used by governments and (b) boosting sharing of private spectrum; and Fueling innovation by opening wireless markets to new players. Despite being known for many years, DSA is still in early stages of its deployment. This is, inter alia, due to various uncertainties and barriers. Below we highlight the most crucial ones: 1. Security, execution, cost, and technology-availability issues: Any spectrum sharing naturally raises interference and hence communications- quality and security risks. DSA is designed to tackle these. That said, any DSA system will naturally face risks and technological challenges and incur costs. Experience from the first major deployments such as CBRS will be crucial for the technology to gain momentum and hence scale economies in the equipment market. 2. Opposition against ending wireless industrys spectrum privileges:As we said earlier, the wireless industry was essentially designed around exclusive use of spectrum. Hence, by default it has become the key owner of licensed spectrum. We therefore expect the industry to push for continued exclusive spectrum allocation on the grounds of quality, security, network investment incentives, etc. The industry is also likely to aim at taking ownership of the spectrum debate, possibly arguing that spectrum sharing is not a new idea and promoting its own sharing models. Equipment vendors may also want to show restraint from pushing a technology with the potential to disrupt businesses of their key customers. \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 43 3. Need for major policy changes leading to possibly lower national budget revenues from spectrum sales: DSA would require a major departure from the existing model of exclusive spectrum allocation. It may meaningfully increase the supply of spectrum capacity, prevent wireless operators from hoarding spectrum to avoid disruption, and allocate spectrum to smaller players at low cost. Therefore, it may dilute the revenues a government can expect to raise from spectrum auctions. This may pose a challenge of finding other ways to raise tax revenue from TMT. 4. Dependence on a strong push by the big tech OTTs: Changing the established policies and the wireless industry may require strong economic reasons and backing. We think that the big tech OTTs (Over The Top Companies) will in the medium term have the strongest interest to see DSA thriving. However, the OTTs have so far shown restraint from openly suggesting sweeping changes in the wireless market. While we think that DSA will play a role in future-shaping the relationship between the OTTs and the wireless industry, there is a range of possible outcomes. We would not rule out the scope for some negotiated outcome between the wireless industry and the OTTs in an attempt to avert the most disruptive scenarios. Impact on Sectors and Companies DSA may shift opportunities from wireless When considering the potential impact of DSAon prospects for different sectors and operators toward tech companies unless the companies, we should reiterate that the technology is in a relatively early stage, former become DIGITECCS hence it may be hard to predict its impact on the financials of major companies. Different scenarios are still possible depending on the success of the technology and regulatory developments but also strategic priorities of the key players, especially on the big tech side. Conceptually, we see the following potential impacts: Global tech: Big tech, but also smaller innovative tech companies, may benefit from (a) opportunities to supply technologies and skills to manage DSA platforms; (b) opportunities to play a role in creatingAirbnb-or Uber-style shared wireless economies; (c) more bandwidth made available by DSA to users globally, which would expand the usage of OTT products; (d) easier opportunities to directly enter parts of the wireless market when needed (e.g., for specific IoT opportunities); (e) fragmentation of the wireless industry and weakening gatekeeper power of wireless operators even if net neutrality is not fully enforced; and (f) possible opportunities to use the disruptive threat of DSA to negotiate future relationships between OTTs and the wireless industry. Telco equipment vendors: Equipment vendors could benefit from the need for more technologically-advanced equipment, although they also have exposure to disruptive risks in a hopefully unlikely scenario of DSAs disruption outweighing its benefits. Industrial & service companies: Innovative industrial/service companies may find it easier to build and operate their private networks. Wireless MNOs (Mobile Network Operators): Wireless MNOs may see their business challenged by harder access to exclusive spectrum and more disruptive competition, both on the regional level and from outside of the industry. The degree of these challenges will depend on various factors, including the spectrum allocations, business models, regulations, disruptor activity, and availability of shared fiber infrastructure. We suggest the MNOs use their (possibly temporary) network and spectrum advantages to build more tech-savvy and service-focused business (we call this DIGITECCS). \f",
      " 4444 GPS: Global Perspectives & Solutions August 2018 However, MNOs could also take an advantage of DSA, which should give them the opportunity to access more spectrum and secure priority rights to such spectrum selectively in regions where they need it. Similar to legacy fixed-line incumbents such as AT&T and Deutsche Telekom, which invested into wireless in very early stages partially to hedge themselves against future disruptive trends, we can envisage wireless operators today potentially investing into new technologies and businesses, including those linked to DSA, for the same reasons. Wireless MVNOs (Mobile Virtual Network Operators): The classical MVNOs and the disruptive role they play may become less needed and appealing under DSA. That said, MVNOs, assuming they have sufficient strategic and capital backing, could also aim at becoming DIGITECCS. \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 45 Asiya Merchant, CFA U.S. IT Hardware & Supply Chain Analyst Amanda Scarnati, Esq. U.S. Semiconductor Consumable Analyst Atif Malik U.S. Semiconductor Capital Equipment and Specialty Semiconductor Analyst\n",
      "\n",
      "7)\n",
      "6. eSports The Rise of the Professional Gamers eSports (also known as electronic sports or professional video gaming) is a form of competition using video games. Most commonly, eSports take the form of organized, multiplayer video game competitions between professional players. Similar to traditional sporting events like the FIFAWorld Cup, sports fans get together to watch their favorite professional teams compete while several millions also tune in to watch a live stream or highlights of the event. These video game tournaments can be played across many devices including PCs, consoles, and tablets, though PCs are predominantly used in tournaments given their computing power and speed. Many genres of games exist that can be played during these tournaments including (1) First Person Shooter Games such as Halo 2, (2) Multiplayer Online Battle Arena (MOBA) games such as Dota 2 and League of Legends, (3) Strategy Games such as Starcraft, (4) Fighting Games, (5) Sports Games, and (5) Racing Games. The newest genre of eSports is Survivor Games like Fortnite Battle Royale and PlayerUnknowns Battlegrounds (PUBG). eSports Evolution eSports has been around for some time, probably dating back to organized competitions in universities Spacewar, Atari Space Invaders Championship, and Nintendo World Championships. The availability of high-speed Internet in homes and Internet cafes along with cheaper, more powerful personal computers have paved the way for video gamers to connect with one another to compete, compare scores, and share strategies. Free-to-play online spectator-friendly games then paved the way for the formation of fan bases who congregate to watch and cheer for their favorite players. In 2000, the first eSports association was founded in South Korea to promote and regulate eSports in the country given the tremendous popularity of StarCraft. In 2002, as the player base expanded globally, Major League Gaming was formed to promote video games as a sport. \f",
      " 4646 GPS: Global Perspectives & Solutions August 2018 The average age of gamers has increased with 50% under the age of 35 vs. 75% back in 2003 In 2011, Twitch, an online streaming service which allowed any players to broadcast their own gaming experience to the Internet at large, was launched. Twitch offered an avenue for engagement between the broadcaster and the audience via a chat window where fans could leave comments and connect with the players and each other. The first League of Legends and the International Dota 2 tournaments were held in 2011. In 2014, Amazon acquired Twitch for $970 million in a cash deal to help drive its expansion into the digital distribution of gaming. YouTube Gaming was launched byAlphabet (Google) in 2015. The age range of gamers is another important factor to consider. According to NVIDIA, in 2003 75% of gamers were under the age or 35; today 50% of gamers are under 35. We are seeing a steady increase in the total addressable market (TAM) of overall gamers as younger generations enter the fray and older generations continue to game. We believe that this gamer for life phenomenon will translate well into growing eSports participants and audiences compared with more established sports leagues, which have a strong base of older generation viewers. Additionally, unlike traditional physically demanding sports, gamers can continue to game as they age, creating opportunity for larger tournaments. Given the infancy of eSports, however, professional gamers today tend to be younger than their traditional sporting peers. Where Fast forward a couple more years, and these are the latest stats on eSports. Newzoo, a leading industry expert consultancy firm on eSports and gaming, claims the eSports global audience base comprises 143 million enthusiasts who watch eSports more than once a month and another 192 million estimated to be occasional viewers in 2017. As a comparison, the 143 million eSports enthusiasts fan base is on par with the ~150 million who claim to be fans of American football (based on a study in 2015). \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 47 Newzoo predicts a compound annual growth rate (CAGR) of 14%15% in this audience base. In 2017, there were 588 major eSports events that generated an estimated $59 million in ticket revenues, up from 424 events and $32 million in ticket revenues in 2016. The total prize money of all eSports events held in 2017 reached $112 million, breaking the $100 million mark for the first time. The 2017 International eSports tournament offered a prize pool of $24.7 million larger than the prize pool of the 2017 Confederations Cup (FIFA) and twice the size of the 2017 Masters (golf) Tournament and all but $1.6 million of that $24.7 million was crowdfunded. Twitch TV now boasts more than 1 million monthly daytime viewers on average, bringing its viewership on par with MSNBC and higher than CNN, which averaged 725,000 monthly daytime viewers duringApril 2018. More than 173,000 spectators attended the Intel Extreme Masters event in Poland. League of Legends World Championship 2017 Grand Finals were held in the Beijing National Stadium (previously the 2008 Olympics Stadium Bird's Nest) with over 57 million total unique viewers logging in to see the finals. eSports is being considered as a demonstration sport by the Olympic Committee. The NationalAssociation of College eSports currently has 81 member colleges and universities, with 79 of them providing partial or full athletic scholarships to student gamers. Despite strong viewership vs. traditional sports, profitability and monetization have been challenging for eSports Monetization and Profitability Remain Key Challenges Despite the impressive growth stats listed above, profitability and monetization have been challenging for the eSports ecosystem. Newzoo estimates that in 2017 the eSports economy totaled $470 million, and it is predicted to grow to ~$1 billion in 2018.As impressive as that sounds, it pales when compared with traditional sports such as the NFL, which raked in $1.3 billion in sponsorship revenue in 2017 alone, with total revenues grossing over $13 billion. \f",
      " 4848 GPS: Global Perspectives & Solutions August 2018 The creation of franchised structures could help the development of eSports Growing interest from media and telecom companies should also spur growth of the eSports economy One of the key challenges has been that eSports is still very much in its infancy compared with traditional sporting leagues that were founded almost 100 years ago. Therefore, we believe the industry is still refining the structure that will pave the way for improved monetization. Newzoo estimates that the average revenue per eSports enthusiast is ~$5.49, which pales when compared with $15$50 per fan in revenues for traditional sports like basketball andAmerican football. The global nature of eSports games also makes it challenging to engage a local regional fan base while the ebb and flows in popularity of certain games/genres at any given point could shorten the duration span for making a return on investments, thereby demotivating significant sponsorship. One recent development has been the creation of a franchised structure similar to those of traditional sports leagues in the U.S. (i.e., the National Football League (NFL), National BasketballAssociation (NBA), and Major League Baseball (MLB)). Major game publishers Riot Games and Blizzard Entertainment have now started to operate the NorthAmerican League of Legends Championship and Overwatch League in a franchised structure with regional teams. This structure is helping to transform games into all-round entertainment franchises, attracting more gamers who may choose to adopt it as a career option. A franchised structure also offers greater certainty of the teams participating in the league each year, attracting investments from broadcasters and content buyers, sponsors, advertisers, and their agencies. The Overwatch League has now attracted investments from the likes of New England Patriots owner Robert Kraft, LA Rams owner Stan Kroenke, and others, each who have agreed to franchise fees of $20 million over the next few years. We believe this franchised structure will be replicated across other eSports game leagues domestically in NorthAmerica and could pave the way for uptake in other regions.Another example is that of the National BasketballAssociation, which is the first traditional sports league to have created an eSports partnership with Take Two Interactive Software. Another factor that we believe could spur the dollar growth of the eSports economy is growing interest from both media and telecom companies. With viewership of traditional sports waning, we expect the battle for content to increase over time, and media companies will want to become more involved in owning media rights to content. To this point, ESPN/ Disney and Blizzard Entertainment, the makers of the video game Overwatch, have recently signed a multi-year deal to broadcast the Overwatch League Grand Finals from the Barclays Center in New York. \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 49 Theyve also agreed to broadcast Season 2 in 2019 on ESPN, ESPN2, Disney XD, ABC, and streaming services for the term of the agreement. While ESPN has aired eSports events at other time slots before, this agreement marks the first time that live competitive gaming will be aired on ESPN in prime time and will be the first broadcast of an eSports championship onABC. This is also the first time a network has approved a multi-year agreement for eSports, airing an entire season of the games, and many are comparing this to agreements ESPN enjoys with other major sports leagues (i.e., the NBA). We note media rights (TV and digital) account for 50%+ of the NFL's estimated revenues with FOX, ESPN/ABC, CBS, NBC, Direct TV etc., which pay an average of $7 billion per year to air these games. TV media revenues have been a key driver for continuous NFL revenue growth from $4 billion in 2001 to ~$13 billion in 2016. We expect TV deals similar to those announced by ESPN to continue to be a driving factor for the overall eSports ecosystem. These are just some of the factors in play. As the eSports industry evolves we expect to see significant development in the underlying infrastructure (player salaries, contracts, governance, college sponsorships, media deals) that can help improve the economics for the entire ecosystem. Winners/ Losers Despite the disruption eSports could cause to traditional sport viewership, there are groups that will benefit from its increasing popularity: Media companies that have deep pockets and the overall audience reach to ensure they can get media rights to broadcast the content and maintain their ranking within their viewership base. Large Internet companies that own specialized gaming channels with significant viewership and can demand large sums for rights to broadcasting content and advertising revenues. Specialized hardware manufacturers such as gaming device OEMs, graphics processing unit (GPU) makers (86% of gamers use NVIDIAGeForce GPUs), high-end switch makers, and peripheral manufacturers (i.e., performance enhanced keyboards, mice, headsets, speakers, gamepad controllers like Logitech G gaming peripherals), as these have become necessary equipment for professional gamers as gaming content is becoming increasingly demanding. These brands are now sponsoring eSports teams. Large game developers/publishers that can continue to leverage their current success across multiple genres to attract teams and fans to their games. On the other hand the following industries could see potential disruptions: Traditional sport leagues and franchises as viewership and participation are diverted away towards gaming. One point to note is that even though the Super Bowl remains the largest TV attraction by far, viewership has been declining, with 2018 viewership of ~103 million, down from its peak of 114 million viewers in 2015, according to Nielsen Media. Sporting brands (e.g. athletic wear, athletic footwear, sporting goods stores) typically associated with traditional sports networks. Media networks that are not traditionally associated with broadcasting eSports risk losing viewership and advertising revenues. \f",
      " 5050 GPS: Global Perspectives & Solutions August 2018 Michael Rollins, CFA U.S. Telecom & Communications Infrastructure Analyst Adam Ilkowitz, CFA U.S. Telecommunications Research Team We are on the verge of another leap forward in wireless technology\n",
      "\n",
      "8)\n",
      "7. 5G Technology Enabling Commercial Connectivity at Scale Wireless technologies have made dramatic improvements since the first cellular phone call was made in 1973 on a 2.5 pound, 10-inch long handset. Further progress has been made through the introduction of texting and digital voice (2G), simple data (3G), and broadband data (4G LTE). The chipsets needed to access mobile networks have also shrunk and dropped in price, and wireless connectivity has been added to myriad devices, from mobile credit card readers to remote monitoring systems. The so-called Internet of Things (IoT) and machine to machine (M2M) connectivity has allowed wireless carriers to dream beyond smartphones and imagine a larger addressable market. The initial standardization efforts of 5G technology were completed in June 2018, and preparations have begun to upgrade networks globally. While some carriers have been discussing the potential for 5G technology for three to five years, there remains a skepticism on its use cases among investors. We agree that this is likely a small improvement for consumer smartphones, but see a huge potential for commercial and industrial users that have not significantly benefitted from wireless technologies to date. 5G improves on four central attributes including lower latency, improved device density, improved speed and capacity, and dynamic spectrum access The 5G standards, as proposed by the International Telecommunications Union and developed by 3GPP, improve on four central attributes of the wireless connection that we believe as crucial to commercial connectivity: Lower Latency. Latency is the delay between a request for information being made and the time the transmission begins; that delay will drop below 10 milliseconds with 5G versus 50 milliseconds or more with 4G LTE. While this may not sound like much, it could mean the difference between an immersive virtual reality experience and a disorienting delay between moving your head and the changing view on the display. Lower latency will be key for emerging applications including autonomous driving, virtual and augmented reality, and mobile gaming. \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 51 Device Density. With the 5G standard, it is hoped that the network could connect as many as 1 million devices per square kilometer (0.38 square miles). This is a 10x improvement over 4G and is key to the potential for vast sensor networks that report back on conditions ranging from air quality and humidity to whether a parking spot is available or if a streetlight is out. The Internet of Things depends on networks being able to handle a vast number of intelligent devices and reporting back to the network. Speed and Capacity. As with any generational improvement, 5G will allow for faster average and peak speeds than previous standards. This bump in speeds, however, is being created by using more spectrum than was previously capable before rather than a significant leap in spectral efficiency. We equate wireless network technology to a highway: Spectral efficiency, or bits per hertz, is like the speed limit, while megahertz of spectrum is the number of lanes. The speed limit is expected to rise just 15%20%, while the number of lanes is increasing by 5 10x as we move from 4G to 5G. Dynamic Spectrum Access: A fourth important innovation with 5G is network slicing, or the dynamic allocation of network capabilities based on the application. This would allow, for example, guaranteed low latency and reliability for first responders in an emergency while prioritizing speed for smartphone users. It allows network owners to customize the offer, and their network capabilities, to price the solutions needed by the end user rather than selling a one-size-fits-all product. (See earlier chapter on Dynamic Spectrum Access.) 201509-I..PDF-E.pdf). IMT Advanced is LTE-advanced technology We expect early 5G network deployments to begin in the second half of 2018 and mass production of chipsets in 2019 I..PDF-E.pdf) The initial 5G standard from 3GPP, called Release 15, was completed in June 2018 and can be put into existing networks through a software upgrade on 5G-capable equipment. This equipment has been available for more than a year, and U.S. operators will be first in select markets with a fixed wireless broadband and data- only mobility focus. Moving into 2019, we expect launches in Japan and South Korea as well as the first consumer smartphones. Europe, China, and other major markets will launch from 2020 as spectrum becomes available. Embedded modules for sensors, automobiles, and other IoT/M2M applications will also become available as manufacturing scales and chipset costs fall. \f",
      " 5252 GPS: Global Perspectives & Solutions August 2018 Expect Carriers to Explore New Business Cases Not Possible with Previous Technologies Better wireless broadband has allowed for more-intensive Internet use, including streaming video, but the cost of capacity and chipsets has limited usage to a largely consumer-focused end market. Some have looked to Wi-Fi, with cheaper chips and free unlicensed spectrum, but the inability to guarantee network quality and security limits the potential. Network slicing allows for lower costs than current mobile networks, better security than Wi-Fi, and customization that tailors the offer to the application. The global wireless industry generates $1 trillion of revenue annually, with one connection per person globally as of 2017. While this revenue stream can be grown through incremental connections and greater data usage, pricing pressures from competition have limited growth in recent years. As carriers explore new business cases, new large addressable markets are becoming available. The Internet of Things Expected to Be a Multi-Trillion Dollar Market A 2015 McKinsey study estimated the global IoT market will be worth $4$11 trillion annually by 2025, with spending on IoT technology to be $300$800 billion. The majority of technology spending will be for upstream software services, with just $15$40 billion for connectivity. While traditional telecom companies have been unsuccessful historically in adding services to their connectivity offerings (the dumb pipe problem), many companies are pursuing acquisitions and partnerships to acquire the necessary skillset. Carrier consortia to provide services globally and present a single point of contact for enterprises have also formed, such as the IoT WorldAlliance and the BridgeAlliance. Potential IoT business cases include: \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 53 Using 5G wireless technology could create better private networks Connected andAutonomous Vehicles: Modern automobiles have dozens of sensors that can be used to predict maintenance needs, predict track location, or effect autonomous driving. Embedding data connectivity into the car can make use of that data in ways that are not currently possible, including real-time traffic avoidance, better fleet management, and new ride-sharing business models. The low latency and large bandwidth available in 5G are required, as milliseconds can matter in preventing collisions and the amount of data being created can be massive. Smart Manufacturing: Smart manufacturing can leverage big data analytics to optimize production and manage the inventory of raw inputs into the process, and it has been called the fourth industrial revolution. Manufacturers can use wireless connectivity to monitor environmental factors, automate changes, track inventory, and adjust accordingly. Connecting the entire supply chain could allow for end-to-end tracking and monitoring from raw material to the finished good. Groups globally have formed to study the potential, including the U.S.-based Smart Manufacturing Leadership Coalition. Digital Health: Connected fitness monitors may have been a fad, but Internet- connected medical monitoring devices can improve health outcomes. With enhanced monitoring of patients with chronic illnesses such as diabetes and heart disease, health care providers can monitor whether treatment regimens are being adhered to and detect potential emergency conditions earlier. Other connected devices, such as heart rate monitors or sleep trackers, could track and incentivize better wellness habits among the population in general. Smart es: Governments around the world are looking to IoT solutions to improve services, conserve natural resources, and generally improve the quality of life of the residents. These can range from real-time coordination of traffic signals to ease congestion and tracking parking meter usage to monitoring water and air quality and issuing timely emergency alerts. Sensors on critical infrastructure like bridges, roads, and utility networks could allow for predictive maintenance and avert poor maintenance conditions. Early examples of smart city applications include the monitoring of full street wastebaskets and mass- transit arrival information. Creating small private networks, either in a single building or distributed across multiple locations, has long been the purview of wired access solutions augmented with limited wireless or Wi-Fi networks. With 5G, that could be reversed given the lower cost of installing, maintaining, and updating a wireless network. Imagine a hospital where every machine and device are connected at all times and are freely movable room to room and floor to floor. Office environments can become more mobile and adaptable with employees taking devices anywhere in the building, or even outside the building, while maintaining wireless data connectivity. Barriers to Entry Include Spectrum Availability & Upfront Investment Anyone looking to deploy wireless networks needs access to spectrum, whether through exclusive licenses or unlicensed shared access. The ability of companies to deploy new 5G networks depends on country regulators making that new spectrum available, and will be the biggest hurdle to deployment. Weve seen early access to new licensed spectrum bands through auction in the U.S., the U.K., and South Korea and allocation processes in China and Japan. \f",
      " 5454 GPS: Global Perspectives & Solutions August 2018 Once spectrum becomes available, the cost of deploying the network will be weighed against its revenue-generating potential, process efficiency gains, or whatever the business case requires. This could be a costly endeavor in certain cases, and it may limit interest in investing the necessary capital. There Are Many Potential Winners Wireless carriers are the obvious potential winners as they are committed to keeping up with technology and will look to better monetize the increasing data traffic on their networks. With 5G technology, wireless companies will attempt to widen the lens of their business by addressing devices and use cases that either havent been successfully addressed or were not possible previously. Other potential winners include: Technology companies could create new services based on the improved network attributes. Mobile console-quality gaming and virtual reality are just two examples of services that are made possible by 5G. IT services companies could benefit from using more wireless networking solutions to improve outcomes for their clients. Shifting from wired to wireless could accelerate deployment schedules and increase solution flexibility. Manufacturing companies could see an improvement in supply chain efficiency by better monitoring materials and processes globally. We Expect 5G Wireless Could Displace Existing Technologies Telecom companies that focus on wired solutions could see new competition from 5G wireless networks. Possible areas of competition include a broadband replacement service for consumers as well as more-flexible voice and data solutions for small businesses and branch offices of large enterprises. Other companies that could face disruption from new 5G networks include: Fixed broadband companies, including telecom companies but also cable operators, and alternative telecom providers could be displaced by wireless broadband solutions that can provide similar technical attributes with the benefit of mobility. Network equipment companies that produce technology that could be displaced, such as Wi-Fi and Ethernet, would be at risk if they do not successfully pivot to 5G. \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 55 Martin Wilkie Head of European Capital Goods Research Team Ji Cheong European Capital Goods Research Analyst Although cost competitive, onshore wind is seeing signs of market saturation in certain developed markets\n",
      "\n",
      "9)\n",
      "8. Floating Offshore Wind Farms The Seas the Limit Current offshore wind turbines are restricted to sea depths of less than 50 meters, significantly restricting where they can be installed. Floating turbines could substantially increase the geographic coverage of offshore wind, including to areas with very deep coast lines like the West coast of the U.S. and Japan, and enabling development into deeper waters in Europes North Sea. Offshore wind installations today account for <4% of total wind installations, with the majority of the wind energy installed base being onshore. With onshore being saturated in many developed countries due to land availability and current offshore technology being limited only to relatively shallow depths, floating offshore could substantially increase the addressable market size for wind, allowing governments to hit their renewable energy targets. Floating offshore turbines could also be installed out of sight', and so get around not in my backyard (NIMBYism) in wind farms, which are to some seen as visually unappealing. Some Background Wind power generation is a key part in achieving government targets for renewable energy, and following years of higher volumes and declining costs, onshore wind power is now cost competitive compared with thermal power in many regions. Onshore wind is, however, now seeing signs of market saturation in certain developed markets especially in markets like the U.K., where restrictive planning laws introduced in 2015 have substantially curtailed new developments. This has driven a growing focus on offshore wind turbines, which enable both larger structures (hence more power) and the use of the seabed as opposed to land. Traditional offshore wind turbines are essentially larger versions of their onshore brethren, but they rely on shallow waters in order to be fixed to the seabed. This has prompted the idea of a floating offshore wind-turbine. The floating offshore wind- turbine has two key advantages over the fixed structure, namely access to more productive wind conditions (as better wind conditions tend to be further out at sea), and being further out of sight, away from residential areas. The concept of floating offshore is not new, but the first demonstrators being commissioned in Scotland in 2017, the announcement of a demonstrator in Japan in 2018, and the creation of a development consortium in California, also this year, suggest the technology is on the verge of adoption. \f",
      " 5656 GPS: Global Perspectives & Solutions August 2018 A floating offshore wind-farm in Scotland currently powers 20,000 households Japan launched an experimental turbine in 2013 and is currently considering developing a floating offshore wind-farm A 100150MW floating offshore wind farm is proposed off the coast of California by 2024 How It Works The turbine is mounted on a cylinder filled with ballast, while 'anchors' (essentially large weights, often 100,000+ tonnes each) are attached to the cylinder to stabilize it on a deeper-water seabed point. Cables connected to the turbine transport power to shore. The first-ever floating offshore wind-farm was installed and connected in late 2017, located 25km off the coast ofAberdeenshire, Scotland. The wind farm involved the installation of five 6 megawatt (MW) wind turbines manufactured by Siemens- Gamesa, and it has powered 20,000 households in the U.K. since its launch. With a capacity factor (which measures actual production versus nameplate/maximum capacity) of 65% achieved in the first three months, this figure far surpasses existing onshore wind farms (generally around 30% capacity factor). Japan has also been a country aggressively seeking floating wind-power options due to the depth of its waters (~80% of the country's estimated wind resource is deemed to be in deeper water areas). The country launched its first experimental commercial-scale floating wind turbine (2MW) in 2013 off the coast of Kabashima Island, and it has recently shown progress for an actual utility-scale wind farm with France's Ideol and Japan's Acacia Renewables signing an memorandum of understanding (MOU) for the development of Japan's first floating offshore wind- farm, although construction isn't expected to start until 2023. In the U.S., the Redwood Coast EnergyAuthority (RCEA) recently selected a consortium (including EDPR Offshore NorthAmerica andAker Solutions) for a proposed 100150MW floating offshore project 20 miles off the coast of Eureka, California. The consortium is aiming to complete and connect the wind farm by 2024. \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 57 Floating wind turbines are gest beginning to be recognized and adopted How Being at a relatively nascent stage of adoption, floating wind turbines are beginning to gain popularity worldwide, already having been adopted in countries like Norway, Portugal and Japan, according to GE. France has also recently turned toward floating offshore, with the current renewable energy plan (PPE) aiming for 100MW of marine energy (including floating wind turbines) to be installed by 2023. The country is also currently in the process of installing a 24MW test pilot project off the coast of the Leucate/Le Barcares area, which is expected be completed in 2020. The Offshore division CEO of Siemens-Gamesa, the world's #1 offshore wind turbine OEM, stated that it views the floating wind-farm market the same way we did with (fixed) offshore wind farms in the early beginning an initially niche market that may develop over time into a large market, and that the catalyst for this market to grow bigger would be the cost competitiveness aspect versus the fixed foundation platform. How Big Could the Addressable market The floating offshore wind-market addresses a wide range of water depths of up to 200 meters, giving it a much larger potential than fixed foundation turbines. The Carbon Trust estimates that the majority of offshore wind resource is only utilizable through floating offshore structures. Northern European countries including the U.K., Germany, and Denmark have been pioneers in using traditional offshore in the North Sea, but over half of the North Sea is at depths inaccessible for traditional offshore, but accessible for floating offshore. USA unavailable) \f",
      " 5858 GPS: Global Perspectives & Solutions August 2018 Estimates for addressable markets vary widely by source, and there is a big difference between addressable (sea bed of 60-200 metres) and economically viable the latter point will subject to turbine pricing, subsidies, and the costs and complexities of grid connection. Europe has the largest potential for floating offshore power, with 66% of the North Sea being between 50220m deep. The EWEA estimates that by 2050, if this deep water space is utilized then this could meet the EU's electricity consumption four times over. The National Renewable Energy Laboratory (NREL) has conducted various studies predicting the potential for floating offshore in the U.S. One example is in California (the state with the largest economy within the country), where the NREL estimates 95% of the state's offshore wind resources are in 60m+ depths, with a potential of more than 100GW. Japan has the sixth-largest sea space globally, with one source estimating 1,600GW of potential for the country, although the majority of the surrounding seas are >60m deep. The Japanese Wind Power Association (JWPA) estimates around 620GW potential capacity for offshore wind, with 520GW for floating offshore alone. Based on this, the JWPAset a roadmap targeting 17.5GW of floating offshore installations by 2050. Consultant MAKE forecasts that some 3.4GW of floating wind power could be installed by 2030 globally, and the European Wind EnergyAssociation (EWEA) estimates that by 2050 offshore wind capacity in Europe could reach 460GW (which would be roughly sufficient for providing 50% of power demands) through deployment of deep offshore designs (i.e., floating offshore). Barriers to Adoption Subsidies: As with most renewable energy sources, wind energy has relied on government subsidies, usually in the form of guaranteed Feed-in Tariffs or Tax Credits, in the early stages of adoption, and we think floating offshore would be no different. Despite the U.K. being at the forefront of floating wind power adoption, under the current system floating wind farms will be eligible for subsidies only if they start generating power before October of this year. Trade association RenewableUK had officially called for the U.K. government to give an additional grace period of 18 months, although the government ruled out any amendments to the current structure, ng the need for the technology to be more cost competitive. \f",
      " August 2018 GPS: Global Perspectives & Solutions GPS: Global Perspectives & Solutions 59 Battery storage and UHVDC connectors are two solutions to wind intermittency The Levelized Cost of Energy (LCOE) levels of floating offshore wind are widely expected to go down, although it may be a long time before it gets near cost competitiveness compared with other renewables. WindEurope forecasts LCOEs of floating offshore to decline 38% by 2050, and this rate of decline is similar to onshore (-35% by 2050) and fixed offshore (-41%). Equinor, operator of the Hywind floating offshore wind farm, aims to reach LCOE levels of 40-60/MWh for the wind farm by 2030 (levels that are comparable to current onshore wind LCOE levels). Intermittency: Wind power, similar to other renewable energy sources, is disadvantaged by intermittency in nature (i.e., wind does not blow all the time). To compensate, there are various solutions that are under development, such as battery storage and ultra-high-voltage direct current (UHVDC) connectors (to balance with other uncorrelated renewable sources like solar). Utility-scale storage solutions are still in their nascent stage of adoption and are generally considered to be expensive, although costs are expected to come down as these solutions become more prevalent. Winners and Losers Winners Turbine OEMs: Floating offshore technology presents new opportunities for the global wind turbine OEM players, especially to those that currently have exposure to the fixed offshore business. HVDC / cable / interconnects: There are a few different types of cables and equipment involved in the power transmission process. Inter array cables interconnect the turbines within the wind farm, through which electricity generated goes through to the transformer. From the transformer the electricity goes through export cables, which then are delivered to shore. Given the longer distance of floating offshore turbines from shore, cable costs will be of much more significance, especially when considering that it costs around $2 million/km for an HVDC cable. Energy storage: The intermittent nature of wind power necessitates increased means of energy storage to compensate. The most recent example of a large- scale battery project is Tesla's 100MW-scale 'giant battery' connected to a 325MW wind farm in SouthAustralia, with the battery cost estimated to be around $50 million. IRENA estimates that global battery storage technology could reach 175GW in 2030 (a 17-fold increase from the 2GW in 2017). Losers Fossil / nuclear power generation: Further technological development and reduction in the cost of renewable energy indubitably shifts demand away from traditional fossil fuels and nuclear power, leading to unfavorable prospects for manufacturers of related equipment. \f",
      " 6060 GPS: Global Perspectives & Solutions August 2018 Roger Ashworth Head of the Non-Agency Mortgage-Backed Security (MBS) Strategy Team Liquidity and transaction speed are meaningful to the average home seller\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-237f4385deb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtxt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput_lst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\")\\n\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtxt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "lst = [1,10,11,12,2,3,4,5,6,7,8,9]\n",
    "\n",
    "i = 0\n",
    "for txt in output_lst:\n",
    "    print(str(lst[i])+\")\\n\"+txt+\"\\n\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "txt1 = \"txttxt\"\n",
    "txt2 = \"txt.txt\"\n",
    "print(re.match(\".*\\.txt$\", txt1) != None)\n",
    "print(re.match(\".*\\.txt$\", txt2) != None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
